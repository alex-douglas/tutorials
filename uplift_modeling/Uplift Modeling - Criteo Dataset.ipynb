{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "### Advertising Campaigns\n",
    "Businesses often create advertising campaigns to increase business performance. The business goal can be increasing the frequency or amount of customer purchases (*deep selling*), encouraging customers to upgrade (*up selling*), trying to sell a new product to customers (*cross selling*), or some other goal such as acquiring completely new customers.\n",
    "\n",
    "When a customer has been targeted by an advertising campaign, we say this customer has been *treated*, while the advertisement itself is the *treatment*. Advertising campaigns can take many forms, and almost everyone is familiar with the most common forms: mailed advertisements, promotional email campaigns, or promoted online search engine results. An important point here is that deploying an advertising campaign costs money -- every letter we mail or online ad we pay for costs something, so it's important that we're targeting the right people. If we send an ad to 100,000 people for \\$0.25 per ad, and none of the customers are persuaded by the ad, we just wasted \\$25,000.\n",
    "### Uplift Modeling\n",
    "**Uplift modeling** is a machine learning technique that allows us to identify those customers most likely to be persuaded by an advertising campaign, while avoiding those customers who are immune to the campaign as well as those who would be less likely to purchase after receiving an advertisement (called \"do-not-disturbs\" -- they could be put-off for a number of reasons, such as being reminded of an active subscription they want to cancel, or being annoyed at receiving an ad). The framework for uplift modeling is rather straight-forward: customers are *randomly* assigned to the *treatment* or *control* group, i.e. to be targeted by the advertisement or not, which allows us to infer the causal relationship between treatment and outcome.\n",
    "\n",
    "For this workbook, I employ the basic \"Two-Model Method\", which involves training two probabilistic binary classifier models on the treatment and control groups. For each sample in a holdout set, I calculate the probability of purchase (or whatever target we've selected for the given problem) if the sample is treated or not treated. The difference is the predicted *uplift* caused by the treatment.\n",
    "\n",
    "An important, if perhaps obvious, point is that we can never know the counter-factual case for each individual in our dataset, i.e. we can never know how a customer would respond both if they were targeted and if the advertisement was withheld. Instead, we must rely on the methodology previously mentioned, which allows us to at least profile the type of customer that responds favorably to an advertising campaign. In future campaigns, we could then run the potential customer population through our modeling framework and select only those most likely to be persuaded by the campaign.\n",
    "\n",
    "The evaluation of this modeling framework is the most critical part of the uplift modeling process, and a bit less intuitive than the modeling step itself. Below I explain each step in the evaluation process, as well as the code that makes this evaluation possible.\n",
    "\n",
    "### CRITEO Dataset\n",
    "For this project, I use the [CRITEO Uplift Prediction Dataset](http://cail.criteo.com/criteo-uplift-prediction-dataset/), which is a collection of 25M individual-level samples from an online advertising campaign. The target is visiting the advertiser's website, and includes 12 randomly projected feature variables for each sample.\n",
    "\n",
    "My step-by-step process is a replication of the work done by the original authors of the dataset, who detail their process in [a paper](https://s3.us-east-2.amazonaws.com/criteo-uplift-dataset/large-scale-benchmark.pdf) released along with the CRITEO dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read in the Data & Sanity Checks\n",
    "Similar to the authors of the original paper, after loading the dataset (available at link in above section), I confirm two things:\n",
    "1. Customers in the control group were not exposed to the advertisement. If customers who were not supposed to be shown the advertisement were in fact shown the advertisement, this compromises the random nature of the experiment and would compromise the causality assumption we're trying to infer from treatment. The authors claimed only a small rate of non-compliance, and dropped those rows from the dataset, so we should find zero rows.\n",
    "2. The features are actually able to predict the target. If the feature variables provided in the dataset aren't able to predict the target (visiting the advertiser's website), there's not much point in the exercise. To confirm this, I train a simple logistic regression classifier and examine its log-loss improvement over a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# typical packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# classification packages\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.metrics as metrics\n",
    "# visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define file location\n",
    "file = '/Users/adouglas/Downloads/criteo-uplift.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the actual dataset is over 25M lines long, and I'm doing this work on my local machine,\n",
    "# I need to read in a subset of the data. Still should be performative enough to accurately model uplift\n",
    "\n",
    "# number of rows to sample\n",
    "sample_rows = 100000\n",
    "\n",
    "# number of rows in dataset\n",
    "num_lines = sum(1 for l in open(file))\n",
    "\n",
    "# index of rows we'll be skipping, for pandas' read_csv method\n",
    "skip_idx = random.sample(range(1, num_lines), num_lines - sample_rows - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the file, with randomly selected subset of rows\n",
    "data = pd.read_csv(file, skiprows=skip_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>treatment</th>\n",
       "      <th>conversion</th>\n",
       "      <th>visit</th>\n",
       "      <th>exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38018</th>\n",
       "      <td>1.991981</td>\n",
       "      <td>3.263641</td>\n",
       "      <td>8.272483</td>\n",
       "      <td>3.735871</td>\n",
       "      <td>3.506733</td>\n",
       "      <td>10.161281</td>\n",
       "      <td>2.981721</td>\n",
       "      <td>-0.166689</td>\n",
       "      <td>1.107571</td>\n",
       "      <td>9.850093</td>\n",
       "      <td>-1.8609</td>\n",
       "      <td>4.157648</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53530</th>\n",
       "      <td>1.991981</td>\n",
       "      <td>3.263641</td>\n",
       "      <td>9.010079</td>\n",
       "      <td>3.735871</td>\n",
       "      <td>3.506733</td>\n",
       "      <td>10.161281</td>\n",
       "      <td>2.981721</td>\n",
       "      <td>-0.166689</td>\n",
       "      <td>-15.258404</td>\n",
       "      <td>9.850093</td>\n",
       "      <td>-1.8609</td>\n",
       "      <td>4.157648</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60852</th>\n",
       "      <td>-1.286884</td>\n",
       "      <td>3.263641</td>\n",
       "      <td>8.272483</td>\n",
       "      <td>3.735871</td>\n",
       "      <td>3.506733</td>\n",
       "      <td>10.161281</td>\n",
       "      <td>0.945163</td>\n",
       "      <td>-0.166689</td>\n",
       "      <td>1.107571</td>\n",
       "      <td>9.850093</td>\n",
       "      <td>-1.8609</td>\n",
       "      <td>4.157648</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             f0        f1        f2        f3        f4         f5        f6  \\\n",
       "38018  1.991981  3.263641  8.272483  3.735871  3.506733  10.161281  2.981721   \n",
       "53530  1.991981  3.263641  9.010079  3.735871  3.506733  10.161281  2.981721   \n",
       "60852 -1.286884  3.263641  8.272483  3.735871  3.506733  10.161281  0.945163   \n",
       "\n",
       "             f7         f8        f9     f10       f11  treatment  conversion  \\\n",
       "38018 -0.166689   1.107571  9.850093 -1.8609  4.157648          1           0   \n",
       "53530 -0.166689 -15.258404  9.850093 -1.8609  4.157648          1           0   \n",
       "60852 -0.166689   1.107571  9.850093 -1.8609  4.157648          1           0   \n",
       "\n",
       "       visit  exposure  \n",
       "38018      0         0  \n",
       "53530      0         0  \n",
       "60852      0         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the data\n",
    "print(data.shape)\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.84537\n",
       "0    0.15463\n",
       "Name: treatment, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's the precentage of 'treatment'?\n",
    "data['treatment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.95953\n",
       "1    0.04047\n",
       "Name: visit, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's our baseline expectation for 'visit'?\n",
    "data['visit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check 1: Are Control Group Members Exposed to Treatment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15463\n",
       "Name: exposure, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be zero positive values\n",
    "data[data['treatment'] == 0]['exposure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check 2: Can the Features Predict the Target? (Or are at least an improvement over chance model.)\n",
    "- For this check, we're simply confirming an improvement over the log-loss of a baseline model, so we don't worry about train/test split, hyper-parameter tuning, algorithm selection, etc. If we didn't see an improvement, then might be appropriate to explore some of these options.\n",
    "- Similar to the authors, I compare log-loss improvement when predicting the target for the whole dataset, as well as just treatment and control groups separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log-loss improvement for predicting 'visit' on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train our model\n",
    "model = lm.LogisticRegression()\n",
    "model.fit(data.iloc[:,:12], data['visit']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10615449409535563"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average log-loss for our trained model\n",
    "log_loss_model = metrics.log_loss(data['visit'], model.predict_proba(data.iloc[:,:12]))\n",
    "log_loss_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.397784280702036"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average log-loss when predicting 0 for all samples\n",
    "log_loss_baseline = metrics.log_loss(data['visit'], [0]*len(data))\n",
    "log_loss_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'92.4% improvement over baseline'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log-loss improvement over baseline model\n",
    "str(round(( 1 - log_loss_model / log_loss_baseline ) * 100, 1)) + '% improvement over baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log-loss improvement for predicting 'visit' on treatment group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train our model\n",
    "model = lm.LogisticRegression()\n",
    "model.fit(data[data['treatment'] == 1].iloc[:,:12], data[data['treatment'] == 1]['visit']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1117019682598608"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average log-loss for our trained model\n",
    "log_loss_model = metrics.log_loss(data[data['treatment'] == 1]['visit'], model.predict_proba(data[data['treatment'] == 1].iloc[:,:12]))\n",
    "log_loss_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.499021382269626"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average log-loss when predicting 0 for all samples\n",
    "log_loss_baseline = metrics.log_loss(data[data['treatment'] == 1]['visit'], [0]*len(data[data['treatment'] == 1]))\n",
    "log_loss_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'92.5% improvement over baseline'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log-loss improvement over baseline model\n",
    "str(round(( 1 - log_loss_model / log_loss_baseline ) * 100, 1)) + '% improvement over baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log-loss improvement for predicting 'visit' on control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train our model\n",
    "model = lm.LogisticRegression()\n",
    "model.fit(data[data['treatment'] == 0].iloc[:,:12], data[data['treatment'] == 0]['visit']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07427827178728018"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average log-loss for our trained model\n",
    "log_loss_model = metrics.log_loss(data[data['treatment'] == 0]['visit'], model.predict_proba(data[data['treatment'] == 0].iloc[:,:12]))\n",
    "log_loss_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443159462766766"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average log-loss when predicting 0 for all samples\n",
    "log_loss_baseline = metrics.log_loss(data[data['treatment'] == 0]['visit'], [0]*len(data[data['treatment'] == 0]))\n",
    "log_loss_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'91.2% improvement over baseline'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log-loss improvement over baseline model\n",
    "str(round(( 1 - log_loss_model / log_loss_baseline ) * 100, 1)) + '% improvement over baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate Uplift and Evaluate Using Qini\n",
    "Under the Two-Model Method, Uplift is calculated by training two separate probabilistic classifiers on the treatment group and the control group. Uplift is then the difference between the probability of a positive outcome when treated versus the probability of a positive outcome when untreated.\n",
    "\n",
    "The critical issue here is the evaluation of the model. A perfect model is assumed here to be one that assigns the highest uplift scores to those customers who have a positive outcome when treated, and conversely assigns the lowest uplift scores to those customers who have a positive outcome when untreated. In this way, we're assuming that the treatment alone is responsible for the positive outcomes among those treated, while we avoid targeting those customers who have a positive outcome when untreated.\n",
    "\n",
    "#### Qini Coefficient\n",
    "To actually evaluate a model's performance, we employ the Qini coefficient (see [here](https://pdfs.semanticscholar.org/147b/32f3d56566c8654a9999c5477dded233328e.pdf?_ga=2.30068543.1667274219.1569778414-2063726560.1569778414) for the original paper on which the Qini is based). It is similar to AUC-ROC in that we calculate the area under this Qini curve and compare it an optimal model. This ratio comparing the Qini of the trained model against that of a hypothetical optimal model is then what we use to compare model performance. The closer our Qini ratio is to +1, the closer our model is to the optimal uplift model.\n",
    "\n",
    "The Qini coefficient is defined as follows:\n",
    "$$Q_{(\\pi)}(k)=\\sum_{i=1}^{k}\\Bigl(R_\\pi^T(i)-R_\\pi^C(i){{N_\\pi^T(k)} \\over {N_\\pi^C(k)}}\\Bigr)-{k \\over 2}(\\bar{R}^T(k)-\\bar{R}^C(k))$$\n",
    "\n",
    "Please refer to the paper itself (beginning of page 4) for definitions of variables. In what follows I'll show the Python code that allows us to calculate the Qini coefficient for our model, the optimal model, and thus the evaluation ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qini Calculation Steps\n",
    "1. Normalize the data\n",
    "1. Split the data into training and testing portions\n",
    "2. Use the Two-Model Method to train two models on our training data\n",
    "3. Calculate uplift on our testing data as the probability difference of a positive outcome when treated and untreated\n",
    "4. Sort the testing data by uplift score, higher uplift values first\n",
    "5. Calculate the Qini score of this ordered data (we'll use several helper columns as this calculation is based on several cumulative values).\n",
    "6. Compare the Qini score of the ordered testing data against a hypothetical perfect model that perfected ordered the data\n",
    "\n",
    "I'll first run through the steps on a single example, then randomize the train/test split and re-run the Qini calculation 30 times. This will give us a sample of Qini ratios that will allow to us to confirm the quality of our evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qini Calculation Step 1: Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature columns\n",
    "feature_columns = data.columns[:12]\n",
    "# normalize using min-max scaler\n",
    "for column in feature_columns:\n",
    "    data[column] = ((data[column] - data[column].min() ) / (data[column].max() - data[column].min() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qini Calculation Step 2: Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define our split ratio\n",
    "split_index = int(len(data)*0.70)\n",
    "split_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 16) (30000, 16)\n"
     ]
    }
   ],
   "source": [
    "# split our dataset\n",
    "train_df = data.iloc[:split_index].copy(deep=True)\n",
    "test_df  = data.iloc[split_index:].copy(deep=True)\n",
    "\n",
    "# confirm shapes conform to expectation\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qini Calculation Step 3: Train Two Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# treatment model\n",
    "model_treat = lm.LogisticRegression()\n",
    "model_treat.fit(train_df[train_df['treatment'] == 1].iloc[:,:12], train_df[train_df['treatment'] == 1]['visit']);\n",
    "\n",
    "# control model\n",
    "model_cntrl = lm.LogisticRegression()\n",
    "model_cntrl.fit(train_df[train_df['treatment'] == 0].iloc[:,:12], train_df[train_df['treatment'] == 0]['visit']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qini Calculation Step 4: Calculate Uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function\n",
    "def calc_uplift(row):\n",
    "    prob_if_treated = model_treat.predict_proba(row[:12].values.reshape(1,-1))[0][1]\n",
    "    prob_if_in_ctrl = model_cntrl.predict_proba(row[:12].values.reshape(1,-1))[0][1]\n",
    "    return prob_if_treated - prob_if_in_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new column in our test set, which is the predicted uplift score for each sample\n",
    "test_df['uplift'] = test_df.apply(calc_uplift, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qini Calculation Step 5: Sort data by uplift score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort our data\n",
    "test_df.sort_values('uplift', ascending=False, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>treatment</th>\n",
       "      <th>conversion</th>\n",
       "      <th>visit</th>\n",
       "      <th>exposure</th>\n",
       "      <th>uplift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.929224</td>\n",
       "      <td>0.916734</td>\n",
       "      <td>0.215150</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.715499</td>\n",
       "      <td>0.139694</td>\n",
       "      <td>0.784842</td>\n",
       "      <td>0.434429</td>\n",
       "      <td>0.600336</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.447053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.797008</td>\n",
       "      <td>0.952201</td>\n",
       "      <td>0.203410</td>\n",
       "      <td>0.158688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671420</td>\n",
       "      <td>0.333397</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.380830</td>\n",
       "      <td>0.394465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.958718</td>\n",
       "      <td>0.357235</td>\n",
       "      <td>0.146227</td>\n",
       "      <td>0.176860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413482</td>\n",
       "      <td>0.220381</td>\n",
       "      <td>0.735459</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.553241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3   f4        f5        f6        f7  \\\n",
       "0  0.929224  0.916734  0.215150  0.011537  0.0  0.715499  0.139694  0.784842   \n",
       "1  0.797008  0.952201  0.203410  0.158688  0.0  0.671420  0.333397  0.797000   \n",
       "2  0.958718  0.357235  0.146227  0.176860  0.0  0.413482  0.220381  0.735459   \n",
       "\n",
       "         f8        f9  f10  f11  treatment  conversion  visit  exposure  \\\n",
       "0  0.434429  0.600336  1.0  0.0          1           0      0         1   \n",
       "1  0.380830  0.394465  1.0  0.0          1           0      1         1   \n",
       "2  0.315113  0.553241  1.0  0.0          1           0      1         0   \n",
       "\n",
       "     uplift  \n",
       "0  0.447053  \n",
       "1  0.430612  \n",
       "2  0.344247  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the data\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qini Calculation Step 6: Calculate Qini of our test set\n",
    "- for this step, we'll create several helper columns to allow us to more easily calculate the Qini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the cumulative number of positive outcomes among treated individuals\n",
    "def calc_tot_num_pos_treat(row):\n",
    "    temp = test_df.iloc[:row.name+1]\n",
    "    return len(temp[(temp['treatment'] == 1) & (temp['visit'] == 1)])\n",
    "\n",
    "# calculate the cumulative number of positive outcomes among untreated individuals (control group)\n",
    "def calc_tot_num_pos_cntrl(row):\n",
    "    temp = test_df.iloc[:row.name+1]\n",
    "    return len(temp[(temp['treatment'] == 0) & (temp['visit'] == 1)])\n",
    "\n",
    "# calculate the cumulative total of the treatment group\n",
    "def calc_tot_num_treat(row):\n",
    "    return sum(test_df.iloc[:row.name+1]['treatment'])\n",
    "\n",
    "# calculate the cumulative total of the control group\n",
    "def calc_tot_num_cntrl(row):\n",
    "    return int(len(test_df.iloc[:row.name+1]) - row['tot_num_treat'])\n",
    "\n",
    "# calculates the qini as we move through the ordered data\n",
    "# as the final Qini is based on area under the curve, we'll be summing each of these values in the final calculation\n",
    "def assign_qini_score(row):\n",
    "    qini = row['tot_num_pos_treat']\n",
    "    if row['tot_num_cntrl'] == 0:\n",
    "        return qini\n",
    "    else:\n",
    "        qini = qini - (row['tot_num_treat'] * (row['tot_num_pos_cntrl'] / row['tot_num_cntrl']))\n",
    "        return qini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create our helper columns\n",
    "test_df['tot_num_pos_treat'] = test_df.apply(calc_tot_num_pos_treat, axis=1)\n",
    "test_df['tot_num_pos_cntrl'] = test_df.apply(calc_tot_num_pos_cntrl, axis=1)\n",
    "test_df['tot_num_treat'] = test_df.apply(calc_tot_num_treat, axis=1)\n",
    "test_df['tot_num_cntrl'] = test_df.apply(calc_tot_num_cntrl, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign qini score\n",
    "test_df['qini_score'] = test_df.apply(assign_qini_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need several constants to calculate the final Qini score of our test set\n",
    "TOT_NUM_POS_TREAT = test_df['tot_num_pos_treat'].values[-1]\n",
    "TOT_NUM_POS_CNTRL = test_df['tot_num_pos_cntrl'].values[-1]\n",
    "TOT_NUM_TREAT = test_df['tot_num_treat'].values[-1]\n",
    "TOT_NUM_CNTRL = test_df['tot_num_cntrl'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4676754"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the Qini score of our test set\n",
    "# the absolute value doesn't matter, only its size relative to the optimal model\n",
    "qini_model = test_df['qini_score'].cumsum().values[-1] - \\\n",
    "            (TOT_NUM_POS_TREAT - (TOT_NUM_TREAT*(TOT_NUM_POS_CNTRL / TOT_NUM_CNTRL))) * len(test_df) / 2\n",
    "int(qini_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qini Calculation Step 7: Compare to Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25175889"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the optimal Qini\n",
    "qini_optimal = (TOT_NUM_POS_TREAT**2 / 2) + \\\n",
    "                TOT_NUM_POS_TREAT * (len(test_df) - TOT_NUM_POS_TREAT - TOT_NUM_POS_CNTRL) + \\\n",
    "               (TOT_NUM_POS_CNTRL**2 / 2) - \\\n",
    "               (TOT_NUM_POS_TREAT - (TOT_NUM_TREAT*(TOT_NUM_POS_CNTRL / TOT_NUM_CNTRL))) * len(test_df) / 2\n",
    "int(qini_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1857632065221253"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can finally get the Qini ratio!\n",
    "qini_model / qini_optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Area Under the Curve\n",
    "- Visualizing the ratio is very helpful in understanding what an optimal ordering of the data would look like, so below we create a graph showing what the Qini would look like when the data is ordered optimally, what it actually looks like with our model, and a baseline when positive outcomes are assumed to be uniformly distributed throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimal line\n",
    "optimal = [i for i in range(TOT_NUM_POS_TREAT)] + \\\n",
    "          [TOT_NUM_POS_TREAT for i in range(len(test_df) - TOT_NUM_POS_TREAT - TOT_NUM_POS_CNTRL)] + \\\n",
    "          [TOT_NUM_POS_TREAT-(TOT_NUM_TREAT*((i+1)/TOT_NUM_CNTRL)) for i in range(TOT_NUM_POS_CNTRL)]\n",
    "        \n",
    "# baseline scenario\n",
    "baseline = [(TOT_NUM_POS_TREAT - (TOT_NUM_TREAT*(TOT_NUM_POS_CNTRL / TOT_NUM_CNTRL))) / len(test_df)*i for i in range(len(test_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAE8CAYAAACFExa4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl8XHW9//HXzGTf925Zu31py07ZQRZxQUFUxAXcFfUK\nAv5AUUARhQsqoqAiUFTEjStw8Spe1KuC7PsO5QstTbM0adI0y0z2mTm/P85kkrRJOm1nMjPJ+/l4\n9NGZM2fmfHoeTfLJd/l8PI7jICIiIiKpwZvsAERERERknJIzERERkRSi5ExEREQkhSg5ExEREUkh\nSs5EREREUoiSMxEREZEUkpHsAOKps9Of8LogpaV5dHcPJPoy84ruaXzpfsaf7ml86X7Gn+5pfM3W\n/aysLPRMdVwjZ7spI8OX7BDmHN3T+NL9jD/d0/jS/Yw/3dP4Svb9VHImIiIikkKUnImIiIikECVn\nIiIiIilEyZmIiIhIClFyJiIiIpJClJyJiIiIpBAlZyIiIiIpRMmZiIiISApRciYiIiKSQuZU+6Z0\n4n/2GQbta8kOIyX4czMZHBxNdhhzhu5n/OmexpfuZ/zpnsaHNy+PspPfnewwlJwlS8evbyPk9yc7\njJTQk+wA5hjdz/jTPY0v3c/40z2Nn9yly2DJ0UmNQclZEjjhMKFAgOz6BhZ+4lPJDifpSkvz6e7u\nT3YYc4buZ/zpnsaX7mf86Z7uvb7HH6P7b/cRHk3+CKSSsyQI9/eD45BZVkZ2TW2yw0m6/MpCBgo0\nihgvup/xp3saX7qf8ad7uvcy3njdfRAOJTcQtCEgKUIB9wvIV1CY5EhEREQEwON1UyInHE5yJErO\nkiIUCADgKyhIciQiIiICQCQ5I6TkbF5SciYiIpJaPF4foJGzeUvTmiIiIqllbFpTa87mqbGRM69G\nzkRERFKDT2vO5rXxaU2NnImIiKSCsWlNlJzNT1pzJiIikmK8HgAcbQiYn8bXnCk5ExERSQUaOZvn\nQoEA+Hx4c3OTHYqIiIhAtJSGow0B81MoEMCXn4/H40l2KCIiIgJ4fGO7NTVyNi+FAn5tBhAREUkl\nqnM2fznhMOGBAa03ExERSSHR9k0hTWvOO2NNz5WciYiIpJCxIrSORs7mHXUHEBERST3jI2dKzuYd\n1TgTERFJQdFSGprWnHc0ciYiIpJ6PNH2TU6SI1FyNus0ciYiIpJ6oo3PtSFg/lHTcxERkRQ0VkpD\nGwLmH01rioiIpB5PpLcmKbAhIGNXJxhjlgFHAL8DbgYOAr5srX04hvceDnzXWnu8MWY5cBvgAC8D\n51hrw8aYs4HPA0HgSmvtvcaYXOA3QBXgBz5hre3ck39gqgkF+gFNa4qIiKSUaBHa9JjW/CUwApwG\nrAT+H3Dtrt5kjPkqcCuQEzl0HXCZtfZYwAOcZoxZCJwHHA28A7jaGJMN/AfwUuTc24HLducflcrU\n9FxERCT1pFv7phxr7Z3AKcBvrbUPAZkxvG8j8P4Jzw8B/h15fB9wEnAY8Ii1dtha2wtsAPYHjgH+\nusO5c4KanouIiKSgFKpztstpTSBkjDkdNzn7hjHmvcAux/ystXcbY+onHPJYa8f2p/qBYqAI6J1w\nzlTHx47tUmlpHhkZvlhO3SuVlXu+XqxpsJ/MokKqqoriGFH625t7KjvT/Yw/3dP40v2MP93TvTPi\nC7IJyM5yk7Rk3s9YkrPPAV8GvmitbTPGfBj47B5ca2IqWgj0AH2RxzMdHzu2S93dA3sQ1u6prCyk\ns9O/x+8f6e0jo7hkrz5jrtnbeyqT6X7Gn+5pfOl+xp/u6d4L9rk5xNDAMMCs3M/pEsBdTmtaa18C\nvgMMG2N8wNettS/uQQzPGWOOjzw+GXgIeBI41hiTY4wpBlbhbhZ4BHjXDuemPScUUtNzERGRFBRt\n35QOa86MMR8C/gRcD5QDjxljProH17oQuMIY8xiQBdxlrW0HbsBNvv4FXGqtHQJ+BqwxxjyMO3J3\nxR5cL+WEBiJNzws19CwiIpJSfGPtm5KfnMUyrXkxcBTwoLW2wxhzEPAP3FIXM7LWNuKW4cBa+zpw\n3BTnrAPW7XBsADgjhtjSSnisO0C+Rs5ERERSSbo1Pg9Za6MTr9baNiavH5MYqXWTiIhIihpr35QC\nHQJiGTl7xRhzLpBpjDkQ+CLwfGLDmpvUHUBERCQ1jY+cpUcR2nOAJcAg8AvcnZRfTGRQc5VGzkRE\nRFKUN3WK0O5y5Mxa2w98PfJH9oKanouIiKQmj8cDXm9K7NaMpbfmBcA3GS8E6wEca23iq73OMZrW\nFBERSV0erxdSoLdmLGvOLgAOtNY2JTqYuS7kj0xrFmrkTEREJOV4vThhZ9fnJTqMGM55Fdia6EDm\ng1C/SmmIiIikKo/XCymwISCWkbMbgJeMMY8DwbGD1tpPJyyqOUpNz0VERFKY15cea85wk7PfAJsT\nHMucFwr48RUUuIsORUREJKV4fN702K0JDFlrv53wSOaBUCBARnFJssMQERGRqXi9OGmyIeAfxpgf\nAPcBI2MHrbUPJiyqOSja9HxJdbJDERERkSl4vL60GTk7KPL3wROOOcCJ8Q9n7lLTcxERkRTn9aRE\nb81YitCeAGCMKQR81tqehEc1B0XLaKgArYiISEryeH2ER0d2fWKCxVKEdilwB7AM8BhjNgMftNa+\nkejg5pKwymiIiIikNp8XhpM/chZLnbObge9Za8uttWXA1cC6xIY196g7gIiISGrzpEj7pliSswpr\n7V1jT6y1fwDKEhfS3KTuACIiIikuRTYExJKcDRtjopsBjDGHAAOJC2luGusO4NW0poiISEryeL3p\nsSEAt7fm3caY7bhNz8uADyU0qjlI05oiIiIpLl0an1trHzfGrARW4o60NVpr/QmPbI7RtKaIiEhq\n8/hSo33TLqc1jTEfBJ611r6CO535qjHmtIRHNsdo5ExERCS1ebyp0b4pljVnlwEnAVhrNwKHAFck\nMqi5KNTf7zY9z8lJdigiIiIyFa8XHCfpo2exJGdZ1tqtY0+stR24a89kN6jpuYiISGrzeN20KNnJ\nWSwbAh4xxvwe+G3k+QeBxxIX0twU8gfIKC1NdhgiIiIynbHkLJTcTQGxjJx9EXgW+Dzw6cjjLyUy\nqLnGCYUIDw7gy89PdigiIiIyDY/P5z5Ig5Gz/2etvRr4/tgBY8x/ApckLKo5Rk3PRURE0kB05CxF\nkzNjzDVAFfAeY8yKHd5zBErOYqam5yIiIqkvHdac3Q2sBt4K/HvC8SDwnUQGNddEy2ioO4CIiEjq\niiZnIcCXtDCmTc6stU8BTxlj7rHW9s1iTHNOuH9s5EzTmiIiIqnK43UTMndaMwWTswl6jDHODsfa\nrLXViQhoLlJ3ABERkTTgi+yTDIeAzKSFEUv7puiOTmNMJvBe4MhEBjXXqDuAiIhI6vN4JpTSSN7A\nWUylNKKstaPW2juBExMUz5wUikxrerXmTEREJHX5Un9DAADGmI9PeOoB1gAjCYtoDtK0poiISOrz\nTCylkbxZzZjWnJ0w4bEDbAM+lJhw5iZNa4qIiKSBsQ0BqT5yZq39lDGmJPK4J/EhzT2hQEBNz0VE\nRFKcx5cG7ZuMMWcZY94AuoAuY8wbxpgzZye0uSPUH1DTcxERkRQ3aUNAEk2bnBljzgAuA84DioAK\n4ALgm8aYD8xOeHNDyB/QlKaIiEiqS4PemhcC77LWboo87wf+Yox5DbgDuGt3LxYpxfEroB4IAWfj\ndhy4DXc928vAOdbasDHmbNxm60HgSmvtvbt7vVTghEKEB/rx1dQkOxQRERGZQaq0b5ppWjNnQmIW\nZa3dCOzp4ql3ARnW2qOAbwNXAdcBl1lrj8XdDXqaMWYh7ojd0cA7gKuNMdl7eM2kCg30A+qrKSIi\nkvImtW9KYhgzvJZnjMnb8aAxJp89L832OpBhjPHiTpWOAocw3rvzPuAk4DDgEWvtsLW2F9gA7L+H\n10wqNT0XERFJDx7fxPZNyTPTtOYfgFuNMZ+21g4BGGOKgZ8Dv93D6wVwpzRfw13DdgrwFmvtWHso\nP1CMm7j1Tnjf2PEZlZbmkZGR+JK+lZWxrx/r7XCz78Kq8t1633yjexNfup/xp3saX7qf8ad7uveG\nCnLowl2SlMz7OVNy9i3gVmCrMWZ95NyVwG+A/9zD630Z+Ju19uvGmBrgX0DWhNcLgR6gL/J4x+Mz\n6u4e2MOwYldZWUhnpz/m8/0tHQAMe7J2633zye7eU5mZ7mf86Z7Gl+5n/OmexsfAUNB9EA7Pyv2c\nLgGcNjmz1gaBTxpjvgWsxV2w/6S1tnkv4ujGncoE2I5bf/c5Y8zx1toHgJOB+4EngauMMTlANrAK\nd7NA2gkH1B1AREQkLXhTo5RGLEVoG4HGOF3vh8AvjDEP4Y6YXQI8DawzxmQB64G7rLUhY8wNwEO4\n6+IuHZtaTTfqDiAiIpIeUmW3Ziztm+LGWhsAPjjFS8dNce46YF3Cg0qwUEBNz0VERNJCimwImLFD\ngOy9kKY1RURE0kKqdAiIaeQs0rJpDW5dsg9Ya29PaFRziKY1RURE0oRvfFozmQ0XdzlyZoy5Brd4\n7Ptxk7lPGWN+kOjA5go1PRcREUkPY2vOSOEitGPeAXwMGLLW9gFvw91VKTEIBdT0XEREJB14vJE1\nZyncvmnMWIRjhWKzJxyTXXCTM01pioiIpDxfaqw5iyU5+wPwX0CZMeYC4EHgdwmNao6INj1X6yYR\nEZGUN74hIMVLaVhrv2uMeQewGagFLrfW3pvwyOaAUL+anouIiKQNX5rUOTPG/BG3ZdOl1tqRxIc0\nd0TLaCg5ExERSXmeFOkQEMu05jrgvcBGY8ytxpjjExvS3KEyGiIiImkksiGAVN8QYK39i7X2o7hN\nz/8K/MAYsznhkc0BGjkTERFJH54U2RAQaxHa1cCHgTOAZuBHiQxqrggrORMREUkfnvRZc/YSEMRd\nd3aitbYt4VHNEZrWFBERSR8eX2rUOYtl5OxMa+1LCY9kDtK0poiISBpJkQ0B0yZnxphbrLWfA24w\nxjg7vm6tPTGhkc0BYyNnXiVnIiIiKW+8fVPqjpzdHPn7W7MQx5w0PnKmaU0REZGUl+ojZ9baZyIP\nP2Ct/dLE14wxvwL+ncjA5gI1PRcREUkf0d6aqZqcGWNuBZYCa40xa3Z4T0miA5sL1PRcREQkfXjS\noEPAlUA9cD1wxYTjQWB9AmOaM0KBABmlpckOQ0RERGLhTY3emjMVoR2y1j4AnApsmvCnGdAK911Q\n03MREZH0Em3flMIjZ7cCp+CuLXOAiXNzDu6Up0xDTc9FRETSTBpsCDgl8nfD7IUzd4wXoFVyJiIi\nkg480d6aKZqcjTHGHAYcA/wEuBc4CPiCtfbuBMeW1lRGQ0REJM2kyIaAXTY+B24AngE+AAwChwBf\nS2RQc4G6A4iIiKQXT4pMa8aSnHmttf8G3g3cZa1tIsaG6fOZpjVFRETSjDc1emvGkpwNGGMuBN4K\n3GuMOR/wJzas9BfWtKaIiEha8aRBKY0xZwH5wPustd3AYuDMhEY1B2haU0REJM2ky7SmtbYVeBo4\n3RjzI+BRa21LwiNLc+PTmho5ExERSQce39huzRQfOTPGfBW4HGjCLUJ7qTHmkkQHlu7GRs68GjkT\nERFJD163pGuyR85iWdj/UeBwa+0ggDFmHe7uzf9MZGDpTk3PRURE0osnjTYEeMcSs4gh3P6aMgO3\n6Xmhmp6LiIikizRo3zTmX8aYu4HbIs8/AfwrYRHNEaGAn4zSsmSHISIiIjHyeDzg8aTFtOb5wBeA\nj+OOtP0LuDmRQaU7t+n5AL6a2mSHIiIiIrvB4/MlfUPAjMmZMWZ/YAXwF2vtz2YnpPSnpuciIiJp\nyutN+sjZtGvOjDHnAA8AXwGeN8acPltBpTuV0RAREUlPHq836WvOZtoQ8EVgH2vtEcAJwEWzE1L6\nUwFaERGRNJXKI2fAiLW2A8Ba+wJulwCJgZIzERGR9OTx+pLevmmmNWfODs/jUj7DGPN14D1AFnAj\n8G/cnaAO8DJwjrU2bIw5G/h85LpXWmvvjcf1Z4OmNUVERNKUL/nTmjMlZ+XGmI9P99xae/vuXswY\nczxwFHA0kIc7VXodcJm19gFjzE3AacaYx4DzgLVADvCwMeb/rLXDu3vNZAhr5ExERCQtebxeCKdu\nKY1/4a41m+q5A+x2cga8A3gJuAcowt1scDbu6BnAfcDbgRDwSCQZGzbGbAD2B57ag2vOOk1rioiI\npKkU2BAwbXJmrf1UAq5XAdQBpwANwJ9wOxCMTaH6gWLcxK13wvvGjs+otDSPjAxfXAOeSmXlzNOV\nPcEh97y6heTs4lxx7eqeyu7R/Yw/3dP40v2MP93T+GjKzCA8OprU+xlLEdp46gJes9aOANYYMwTU\nTHi9EOgB+iKPdzw+o+7ugTiGOrXKykI6O/0zntO/rRuAnmEPvl2cK7HdU4md7mf86Z7Gl+5n/Ome\nxk/I8UAoPCv3c7oEMJbemvH0MPBOY4zHGLMYdwfoPyNr0QBOBh4CngSONcbkGGOKgVW4mwXSQijg\nV9NzERGRNORJ8Q0BcWetvdcY8xbc5MsLnANsAtYZY7KA9cBd1tqQMeYG3ETNC1xqrR2azVj3RijQ\nr6bnIiIi6ciT/Dpn0yZnxpj72bmcRpS19sQ9uaC19qtTHD5uivPWAev25BrJpqbnIiIi6SnVe2t+\na7aCmEvU9FxERCSNpUCHgJl2a46Vt8AYcxBQAHgAH+5Oy39P89Z5TU3PRURE0lcq9Nbc5ZozY8yv\ncAvHluGuCTsQeAT4RWJDS0/qDiAiIpK+PD5f0pOzWHZrvgVYDdwJfA44HLf1kkxBBWhFRETSmMcD\n4TCOM+2y+4SLJTnbYq0dxR01299a+wqTa5DJBCH/2MiZkjMREZF04/FFitkncfQsllIarZFm5f8A\nvmeMAXf9mUwh1D82cqb8VUREJO143XErJxwaT9RmO4QYzvkMsMla+xTw38BHgC8kNKo0Fm16Xqj8\nVUREJN14IskZoeSNnMWSnJ1rrb0DwFr7Y2vtabjNyWUK0WnNfCVnIiIiaScyWpbMTQEzFaG9BqgC\n3mOMWbHDe44ALklwbGlJ05oiIiLpy+OJjFulYnIG3I27S/OtTK5pFgS+k8ig0llI05oiIiLpyze2\n5iwFk7PIGrOnjDF/tNb2zmJMaW2s6bknW03PRURE0k10zVk4eV0CYtmt+V5jzA+A0shzD+BYa5Oz\nhSHFqem5iIhIGhvbrZnEDQGxJGeXA8dba19OdDBzgZqei4iIpC+PN/l1zmLZrdmqxCw2TjDoNj1X\nAVoREZH0NKHOWbLEMnL2jDHmLuDvwNDYQWvt7QmLKk2p6bmIiEh68/hSe7fmmGLADxw54ZgDKDnb\ngcpoiIiIpDlvCu/WHGOt/RSAMabUWtud+JDSl8poiIiIpJ/A4Chhx6EoLyu65swJpfC0pjHmAOC/\ngDxjzBHAg8AHrbXPJjq4dKPuACIiIuklHHY47/qHyM0N88Wzatiw2bIKGBkZJVlFsWKZ1vwx8D7g\nd9baLcaY/wBuAg5LaGRpSNOaIiIiiRMKh2np6Oefz7Tg8UBZUQ6nHdMQfX1b7yC/+fvrtHcNsGxJ\nMSuqi6kszWVRWR5lRTkTPifElv6tNPY18deXXiB7v3acnH5ufBH2LRtkhQ9aRkZZnYx/JLElZ3nW\n2vXGGACstf9njLk2sWGlJzU9FxERmV5X7xAvbNzGy29uZ0FZLnk5mfj7R6hZUEBVSS5F+Vn0DwbZ\n2j1A38AIJfnZeL0eXm3czkMvtk35mf1DozzyUhtF+dls3T4QPd7RM8hjr7S7TzKHOHB/H22DreSW\nBdg20k6IoPtaFnhCPsL+MsKBYp4Jl/DssiKuX7piiqvNjliSs+2RqU0HwBhzFrA9oVGlKU1rikzW\n0TNIa0eAlbUl5OdkJjsckTmhf2iUja29tHT2s7gin9KCbDKyM3nguVZat7lVA7IyvdQtKCQr00dB\nTiaBwVE6ewbJy8mgIDeT8qIcmjr8LCzLZ+niIsKOw2gwTGaGF3//CKOhMH397nU6egYZGBolO9NH\n7YJCjjtw8U6F1h3HYSQYprWzn77I+53IGq6cbB9/f7KZx1/dGrd74PN6qCrNpa1rgH883QLA4HAk\nMfMGOfPUKnqdDmzXJlr6W/BkDWMBCqB3GJzBAsKBEsL9xYQDJZy42vDP17ZMukZudvJq7ceSnP0H\n8CtgjTGmB3gD+GhCo0pT0Q0BmtaUeS4cdnijpYfv/u656LGfXHAsedMkaMHIN/LMDDUeEWnr6mdD\nay9H7bsQn3dyOdLWbf1849Yn4nq9g1dWsqGlh76B0ZjOf/SVdjZt6WNJRT5NHYHdulZuto/sTB9v\nOWAxaxrK6A2M4PN56PYP0xMYYXvfENlZPvJzMunoHmBFdQmhUJjAUJBVdaUsXVxEdqb7fWI0GObN\nLb30BrfTNtSKnw42+5tpH9jKPW3jOy3zc/MZ6S0je7SC7e05hPuLyc/KYVFFPqe/bSkrqkvwej14\n8PKPZ9xE77+/ewo93QNT/htmQyy7NTcCxxhj8gGftbYv8WGlp+iaM01ryjwSdhwefamdx19tp7HN\nT8hxGB7ZeZfTuT96aNLz3OwMBoeD037u/svKqa4sIMPnIRR2OPaAxVSV5MY9fpFU0BMY5oHnWmnf\nPsCT6zsA+O3fX+fQfaooLcqmIDeL1s5AdGqvbkEhi8rzWFCWR9/ACH0DozzzWgcHLCvnuIOW4MEd\nuR4cDjIwFKS5I0BPYJiDVlTi8cD2viEee8UdyXr29U58Xg/LlxQDMDQSIjvTS052Br2BYY47cAn7\n1JZw3xNNPPpyOxta3HbbOyZmy6uLKczNpKo0l9ebe1lrKhkYDjI8GsLr8XDQigpMbSl7wz8S4PVt\nTTT2NtHY18xmfzODwWgJVjK9GdQX1VJfVEN9US0NxbWUZpdER/q29Q6SnemjMC9rp88+820rKczL\nZPmS4qT/ohjLbs1jgQuI9NacsPbsxIRGloZCAT+ejAw1PZd5YWv3AF+/+fEZzznuwMW8/dAabrzn\nZTp6BhkNjv82O1NiBvDixi5e3NgVff7Uax3859lH4PWqb62kN8dx6AmM0Ns/zOZ2P01bA9z/XOtO\n540EwzzycvtOx5ctLuLisw4mwzc+qlZZWUhnp3+34jj5iDoef2UrVaW5rDWV045sjznzpJUsKs9j\nYDjIcQcspqIkFw8krJf0aDhIi7+Vxr5mGvua2NTbRNfQ5FVVVXkV7FexmoaiWuqLallSsAifd/rE\nqqJ45l/wTj26YcbXZ0ss05q3AVcAmxMbSvoL+QN48wvU9FzS2uZ2P/94pplw2OGgFZWs3acKcKce\nQyGHN1p7ePyVrTw64YdGUX4W1ZX5vPuIOmoWFOLzesjNHv/28p3PHg7AwFCQzVv9ZGZ4ufrXz+AA\nnzt1NcuWFFMZGRULhx02tfexvrGbzVv9hMMOz72xjY7uQT77vfsByM7ycaip4qAVFYQdeHHjNo5c\ns5CVtSWEQg4eD3T1DREMhrHNPeTlZHDg8goyM7w7TROJzKbn3ujkD/dvnLRwHcDjgdX1Zey3tJyj\n91vIP55uoSA3E1NTwnb/EL39IwwOBTG1pdQtjM/SmerKAj5wfOwzPXk5Gbz7yPq4XHtHjuOwbXC7\nm4T1NdHY10SrfwtBZ3wUPj8jj9XlJjIy5o6O5WfmJSSeZIslOWtVq6bYhPoDanouaenxV9p5cn0H\nbdsHJv3QGJv2mE5xQRbf+czhFOTGttg/LyeDVXXutMbPvzb14LvX62HZ4mKWLS6OHmvpCPDXJ5ui\nCeHwSIiHX2rj4ZfGd29Nt5NrKrVVBWRl+thvaRl1C4tYXJ5HWbE74u3VL1cSB2HHcR848OjL7fgH\nR7jz/o2TzjlkZSULy/NYuriI5UuKJ021TSwPUV0195bKDIwOsjkyIub+aSYw2h993evxUl2wmIbi\n8USsMrdi3gx+xJKc3WCM+Q3wLyA6D6GEbbJo0/PaumSHIjKtcNhhy7Z+3mzr47b7Xpv2vLccsJiX\nN3WxvW94ytfLirK54IwDqK6cnR8a1VUFfPaU1Xz2lNUMDgd5s62PR19qxzZ3MzAUZEFpHqGwQ0vn\n1IuTC/My8U9Y7Dy2VmZDa++U5x+0ooLFFfnULSjEAZ7/y3rKC7M5bFXVtP/mUDjM8EiY3GzfvPkB\nIjAaDPHKpm6GR0M8v2Ebz2/YNuWay4nOOGEZJx8+f35WuDXF2qNTk419zWwd6Jh0TnlOKaZ0ubtW\nrLiOmoLFZPrm7w7vWJKzL0b+PnbCMfXW3EG06Xl+fpIjkfnIcRyatgZ46c0uNrX7CYXCvOuIOlbW\nlNDW1c+6P79Kb/8IoVB42h1ZSxcX8c7DallVX0p+TibBUBj/wCher4eivMyUSThyszNYU1/Gmvo9\nG6UOhx3auvrp6hvmjZYe3tzSx/rNkzvTPffGNp57Y9tO77330UY+e8oqHn6xjfLiHBrb/WRleNmy\nbYDhUfcHclamlw+/dQWDQ0GyMn0MjQTxeb1kZ3oJO27iN7EYpqSfsOPwl0cbueehTTG/58MnLmdo\nJMQRaxZQVTo3p+LGdA/1RKcmG3ubafK3MBoe/76T48tmZenyyDqxGuqLaynKUpWDiWJJzhZZa1cl\nPJI0pzIakmjb+9x1J396eBMvbOwiLzuD3GwfXdOMbk1cTD9RVqaXkdEwK2tKuPBDB5KZMfUarAyf\nl9LC7LjFnyq8Xg9LKgtYUlnA/svKJ70WDIVp2hqgqcPP0HCIzVv9BAZGyM7JZP2mLgaHQ9x67/oZ\nP39kNMztf7XTvv7XJ5r41Lv2YXvfMFmZ7r0/eGUlGT6vu+6md4j8nIxdLs6W2RMKh2nfPsjLb3bx\nwoZtdPYM7vR19+4j63ijuYcVNSUce8BiKopy8Ho9BENhfF5PyvxyE29DwWGa/S2RZKyZxt4mekfG\nizp48LC4YGF092R9US0L86vwerT2cyaxJGcPGWNOAf5qrZ15e9U8pjIaEi+O49DY7ucXf1nPmoYy\nHAfuf67GCEz3AAAgAElEQVSFYMiZdN7AcJCBKXY8HmyqeNZ27HT8PUfXc9yBS+ZkwhUvGT4vSxcX\nsXRx0aTjlZWFPPdKG9+/4zn8A6P4vB7OfNtKDl5ZSVaGl7DjkJuVwT0PvclTr3Vw2KoqgiE30eoN\nDLOoPB+f18P9z7XS1TfEtXc8H1M8Bblu8dAMn5crzz5cpUQSqH9olA0tvWzrHWJkNOTW3eofYWQ0\nxOvNPQztMFXZsKiITW19FORmct25R0/aOTnRdMfTUdgJ097fEd092djXxJZAOw7j35uKswo5oHLf\naDJWW1hNToa+5+yuWJKzU4HPAhhjHMADONZaVYucQN0BZE+MBsPc9D8v0759AI/Hw/a+oUk/BMaq\nfe/orLetpLwoh5bOQHR91Nhv5pWVhWzYtI3A4CiLyvPBo0Xu8VBdVcD15x074zmnH7eM049bNu3r\nh5hKXmncTnffMKWF2fQERsbby0SUF2WTm51JS2cAJ7KoPBgK87WbHuPth9bwoROXz9lRmNnS7R+m\nq2+IrdsH6Oodwjb37DS1PVF2po+1+1SxfHERK2pKaFhUNO25c4l/JDBhnVgTm/taGApNrCmWydLi\nOndErLiWhqJaSrKL9f8zDmIpQrtoNgJJd5rWlFh0dA/Q2tnPj//7pZjOX11fSktHgFOPbuCEg5bs\nVOPrwBUVU76vuCCb4gL9tppqVteXsXrCWjnHcSgpzOL/nmrm/W9ZxjsOq9npB9umtj6+86unAfj7\nU8109Q2xb0MZrzf3UFGcy6KKPF7c2EWGz23Xs7A8j9HRMD6fh0XleeRlT54iDYXDhMMOgcEgJQVZ\nc/IHaW9g2C09MRyko2eQ3sAIBXmZ3Hn/BpYtKeaVTdtxJg9EU12Zz4qaEqorCygpyKIwL4uK4hyy\nMrxkZfrm1AjYVEZDozQHtkTWibnJWNfQ5IR1QV4lBxStiSRjNSzJn7mmmOy5WIrQZgEXAQb4Em5B\n2mustSMJji2thDWtKTNo6+rn0nXTt1ypqSqgo2eQvOwMjjtgMaceXT8nf2jKZB6PhzOOX84Zxy+f\n9pyGRUX8/OIT+ONDm/jzo408Yzt5xnZOee7D7FxOxOf18PWPHkLDokL++mTTpHIOudk+BodDrKor\npbggC8eBypIcXm/upbNnkEyfl6KCLLb1DLKqrpSGRUW8uaWP7Cy3x2JOpg88sKa+jKL8nSuuz4ZN\nbX08bTto2hpgW88g/UNBAoPTtyF6+c3tLCjN5YDlFYTDDqa2hKrSPJZU5s+bEWbHcegc7BovY9Hb\nTEtgC6GJNcUy81hTvg/1RTU0FNVRV1RN3hytKZaKYpnW/CnQCRyCW0pjOfBz4GMJjCvtRKc1NXIm\nuNMmV/366WlLUQAcvnoBnzp5H7Iy9ZunzMzj8fCeY+o5aGUFXb3DdPuHeHnTdmoXFJAXmQLN8Ln1\n4dq2D5Ad2SX6j6dbCIUdrrz96Sk/122hFZpxSq+jZxBwa95NV/cuw+fh3PfvT262j1v+9CqLKvJY\nUpFPt3+YkdEwy5YUkZudwYMvbKGkIJv27kFK87P4ykcOmjQaHBh0G22PBsNsaO2lJ+B+/Zx4cDUr\na0oYHg3xrO3k9ZYeXtzYRbd/8tdXdqaP3Gwfa+pLKcrPJjvLx8LSXMqKcvAPjtLW1c8x+y2ipmp+\nFQsfGB0Yr7Lf18Tmvmb6R8frGfo8PqoLFlNfPN72qDK3fF7do1QTS3J2iLX2YGPMydbaAWPMJ4DY\n5mTmkei0ptaczTuO4y6H3dDSy/MbtvHXJ5qmPfeHXzqG4iSNMEh683m91C8son6h+/yktTW7fM/b\n1tbw03teprnDP2lDya0XnxAdJfIPjBAYHKWrd4jGdj+VJbmUFmZTWZJLdqbbUaGx3d191zVhTeTw\naIj+wSD/+/hmgiGHH935QvTzu/qGePnN8TY7z28YL0vStNX9XtmxfYBr73gu+stJt3+Y5mmaaD+5\nvoPSwuydkjFwe0wevnoBB62ooKo0d94nFKFwiNb+tmjvyca+JrYOTB5pLc8pY5/SFdF1YtXzvKZY\nKoolOXMiU5tjX9kVEx5LRCgQGTnTtOac98KGbVx/14u79Z6Lzzxorxv+iuyusqIcvvGJtQRDYQaH\ng1M2ey7Mc9dXLSrPZ9+l5VN8CjP+361bWMiDL2yhtCCbzEwvI6MhDlxeQW52RrTI78KyPLr6hnhl\n03bed+xSugIjrPufl3mtqWfSZ1UU57B0cRFVpXksLs+jbmFhdDmAf2DUXRdWXcIRaxZQVphDaWH2\nvO616jgO3cM9blHX1nZebd9As7+F0fD4Lu4cX46biEXqidUX1VKYpZ9TqS6W5OxHwD+AhcaYHwHv\nw+21uceMMVXAM8DbcKdKb8NN+F4GzrHWho0xZwOfj7x+pbX23r25ZqKF+gNqej5Hbe8b4qf3vMym\ntr5dnxxx1ttW8tZDqhMYlUjsMnzeKROzeDh0nyoOjfRf3dHqHQoFj1XFP6KykH3rSugfCpKbnUHY\ncSjMnbrQ8TVfOBIcZ84Xbo3FUHCYJn9LdMF+Y18TvSPjzc7Ha4q5I2L1xbUsyKtUTbE0FEtydh9u\nInUC4ANOtdbu3rDBBMaYTOBmYDBy6DrgMmvtA8aYm4DTjDGPAecBa4Ec4GFjzP9Za6dfwJNkano+\ntwyNBLn7gTf557Mt055zxOoFFOVn8Z6j61UwVGQ35eVkxvR1M19ru43XFGuKlrNo69+6Q02xIg6s\n3Jf6oloOrDUUhspUU2yOiKkIbaRDwKtxuua1wE3A1yPPDwH+HXl8H/B2IAQ8EknGho0xG4D9gafi\nFEPchQJ+MsqmnhKQ9NDRM8jXbnpsxnOu+fwRFORmkZcTy5eOiEhseof9k5qAN/U1MxQaH49wa4rV\nU1/s7p6sL6qhNKck+nplZSGdnf6pPlrSUCw/YV4wxnwMeJLx0S6stdOvep6GMeaTQKe19m/GmLHk\nzGOtHftVwA8UA0XAxI7EY8dTkhMMEh4cxFeonZrpJOw44MCDL26Zsd3OTRcepx2VIhI3bk2xVhp7\nm6Jtj7bvVFOsigMj9cTqi+pYnL9ANcXmkViSs8MjfyZygKV7cL1P424wOAk4ELd5+sTFCoVAD9AX\nebzj8RmVluaRkZH4/7yVlZOTsJEeN7S88pKdXpPYJPK+hUJhHn2pjaP2XwzArX98ic6eQZ7YoTL7\nmKv+4yhe2djFB966ctq+k6lO/w/jT/c0vubL/XQch/ZAJ290beKNrk1s6GqksaeZkBOOnlOYXcDB\ni/ZlRXkDK8obWFZWR37W7q+xmy/3dLYk837G0iGgwRiTaa0djawXy7bWTr3fedef9Zaxx8aYB4Av\nAN83xhxvrX0AOBm4H3eU7ipjTA6QDazC3Swwo+7ugV2dstemGjoebnV/yAczcjSsvAcSMRwfdhwe\nebGNDJ+XdffGNiNfWpjND845GoBFBy+hp3vq1kmpTtMb8ad7Gl9z+X72T6gp1tgbqSkWHP/ZlOHx\nUVNYHa0n1lBcS3lO2aT1ygO9IQbYvfszl+9pMszW/ZwuAYylQ8AZwDeB/YBa4AFjzLnW2v+JU2wX\nAusi5TrWA3dZa0PGmBuAhwAvcKm1dmimD0kmldFIDY7jsKnNP23BzalcfOZBZPi8LFuSsrPmIpKi\nQuEQrYG2yNSk+6djYNukcypyylhVvtJteVRUS3XhYjK9WrMqM4vlf8g3gJMArLUbjTGHAH8H9io5\ns9YeP+HpcVO8vg5YtzfXmC3qq5kafv+PN/jHM1PvrszO8jE8EmJReR5XnX3ELEcmIunOcRy2D/VM\nWLTfRLO/deqaYhMq7aummOyJWJKzLGtttGeHtbbDGKN6EROoO0Dy3Xbfeh58YbyvYGVJDt/+zOFk\nZXhV3kREdttQcIjNfS3R3ZOb+jbjHxlf0eP1eFmcvzBS3LWOhqIaqlRTTOIkluTsYWPM74HfRp5/\nEJi53sA8o2nN5AmGwjz0Yls0McvNzuCnX37LLt4lIjIu7IRp698aXSfW2Ne8U02xkuxiDqzcz20E\nXlxHTeESsn1qxSaJEUtydg5uQdjPA6PAg8CNiQwq3YQ1rZlw4bD7TXJb3xA4DjnZGVxww8M7nfeT\nC46d7dBEJM30DvdFR8Qae5vY7G9mODQSfT3Lm8mykvpoPbH64lpKsrUuVWZPLLs1h40xNwN3AGPz\nQwuB3a5zNldpWjNxtvUOkp+TyTk/fHCX597yleM1hSkik4yERmn2t7pV9iMjY93D45WZPHhYkF81\nvnuyqJZFqikmSRbLbs1LgK8BXbj1zTzseZ2zOUnTmvHnOA6f+e79uzwvM8PLTRcep6RMRAg7YToH\ntkVLWWzqa6I10EZ4Qk2xgsx89i1fRUOkCXhdUTW5GfOzRZSkrlimNT8DLLPWdiY6mHQVCqjpebx0\n9AxSnJ/FZeuemPL19x7TwMlH1LLdP8wCNUIWmdcCo/1s7mtmU6QR+Oa+ZgaC0UY2ZHh81BVWR8pY\nuAv3y3NK9cucpLxYkrMmYHuiA0lnoUAAb4Ganu+JcNjh1Aunr8rysbev5PiDlux0b5WYicwvwXBw\nvKZYbzONfZvpHOyadE5Fbjlryvdxk7HiGpYUqKaYpKdY/te+gbtj834gWgjWWvvthEWVZtT0fM/9\n8A/Pz/j6CQdXz1IkIpIq3Jpi3RPWiTXTHGglOKGmWG5GLqvKVkbXitUX1VKQlZ/EqEXiJ5bkrDXy\nB8Y3BEiEmp7vvpnWk+27tIy3HlzNvkvL8HlVL0hkPhgMDrG5r3lS2yP/6OSaYkvyF1JfXBdNxqry\nKlRTTOasWHZrXjEbgaSrUL/bf9FXoM0Au7K1e4Cv3/z4lK/94msnznI0IpIMYSfM5p4Wnm1dH03G\n2vs7JtUUK80u4aDK/SKV9mupLVxClmqKyTwybXIWmcZ0pnvdWqufpqiMRqxC4fCUidnFZx7EMYfU\nqmGvyBzVM9wbrSfW2NfEZn8LIxNrivmyWF7SEFkn5i7cV00xme9mGjn71mwFkc5URiM2Z3/vgUnP\nD1tVxRdO2zc5wYhIQoyERmiK1BQbq7S/Y02xhflV7FO1jIVZC2kormNhXpVqionsYNrkzFr779kM\nJF1FkzN1B5jWpra+6ON3H1nHmvoy9qkrTWJEIrK3wk6YjoFtEyrtb6a1v31STbHCzAL2q1gdLWVR\nV1RDbkYOlZWFGi0XmYH2GO+lUEBrziYKhx283vF9I1u7B/jOr54GoDg/i9OPW5as0ERkLwRG+iOJ\nWCQZ62tmcGJNMW8GdYU11BfX0BDZPVmmmmIie2SmNWf51tr+2QwmHY2PnCk5+9GdL/Dixq5pX//O\nZw+fxWhEZE8Fw0FaAlsi9cTcchbbdqgpVplbzr7lq6LJ2JKCRWSopphIXMz0lfQAcKgx5kZr7Rdn\nKZ60E1LTcwDOu/4hAoOj075et6CQgtzMWYxIRGLhOA5dQ9009m6O7p5sDmyZVFMsL1pTrJaG4lrq\nimooyFRNMZFEmSk5KzDG/AZ4pzFmp75E1tpPJy6s9BGOJmfzd+TsGz9/YtrE7BufWEtlSa4SM5EU\nMRgcZHNfizsiFtlBGRgdnyTxerxUFyyKFnatL6qhUjXFRGbVTMnZ24ETgGMBbQ6Yxnyf1nQch9bO\n8W/sP7ngLWzrHaSx3c8RqxeQlaldWCLJEgqH2NK/ddJasa1T1RSr2j+6TqymcAlZPv0yJZJMM+3W\nbAZuN8a8ALwKmMj5L1trg9O9b76Zz03PA4Ojk9ovjRWSrc0ppHbB/J7mFUmGnuHeaAmLTX2baepr\nYSQ8Pqqd5ctiRcnSaD2x+qJairOLkhixiEwlltWbmbj9NbsAL7DAGPM+a+0TCY0sTczHpucDQ0G2\n9Q7yrV8+FT32zsNqkxiRyPwzHBqhKTI9ObZWrGe4N/q6Bw+L8he4SVik0v6i/AWanhRJA7EkZ9cD\nHxpLxowxRwA/Bg5LZGDpIhTwk1FekewwZtW5P3pwp2Pve8vSJEQiMj+4NcU62RSpJ9bY18yWHWuK\nZRWwf8Wa6IhYbVE1uRnzb0RfZC6IJTkrmDhKZq19fKoNAvNRtOn5PFpv9vRrHZOeH7lmIWefujpJ\n0YjMTf6RwITirk1s9jczGByKvp7pzYgmYfXRmmIl82oEX2QuiyU5226MOc1a+z8Axpj34k5xznuh\n/vmzU7Npq3/SNOaYj7/DJCEakbljNBykxb9lfNF+bxPbhrZPOqcqryJaaX+spphaHonMXbEkZ58D\nfmOM+TngATYCH01oVGlivDvA3F78/tgr7az786uTjv3s/x1HdpZ+OIjsDsdx2Da4fdLuyRZ/K0En\nFD0nLyOX1WUmuk6svqiG/My8JEYtIrNtl8mZtfYN4HBjTD7gtdaqIVrEeBmNuVmMMew4fPa79+90\nfK2pVGImEoOB0UE2+5sjlfbdtWI71xRbHE3CGoprqcyt0PSkyDwXc68NtXLa2Vxven75L56c9PzK\nzx7O4oq5mYiK7C23plh7ZGqymU19TWwdmLxGsyynlINLl7k1xYprqS5QTTER2Zkaoe2Fud70fGJx\n2R9fcCz5OfohIjKme6gnWk+ssbeZZv/kmmLZvixWli6ftHC/OHtu/iInIvG1y+TMGPMFa+1NsxFM\nupmL3QHCYYcf/NfzrN/cHT02VlxWZL4aCg7zRvfGaD2xTb1N9I70RV8frynm9p6sL6plYX6VaoqJ\nyB6JZeTsXEDJ2RTmUtPz3v4Rrvnts2zdPjDpuHpiynwTdsJsHeiksbeJTZGF+239WyfVFCvKKuSA\nijXuiFhxLbWFS8hRTTERiZNYkrNmY8y/gCeAwbGD1tpvJyyqNDEXRs6GRoJ88bqdi8qOuf68Y2Yx\nGpHZF60pFknGNve1MBSaXFNsRXkD1blLom2PSrNVU0wklT3yyENcfPGXefjhp3d5blvbFs444z3c\nfvsdLF26fBai27VYkrPHJzzWd6MJwnNg5OzXf7PTvnbLV47XDyCZU9yaYq3uiFikB2XXDjXFFuRV\nckDRmmjboyX5i1i4oITOTm1UF5HZEUspjSsiZTSWAS8Dudq56Rpvep6d7FD2WFvX+DTm505dzS1/\nfpVrv3gUZUWaopH05jgOnYNdkyrttwS2EJpQUyw/I4/V5cbdPRkpZ5GnmmIikmSxbAg4EbgF8AFH\nAS8aY86y1v490cGlulDAnxJNzx3H2aMYwmGHxnZ3NOC6c4+mpCCbI9YsjHd4IrNiYHSQzWO7JyML\n9/tHx3/58Hl8bk2x4vHdk5W55Un/+hWZj445Zi3f/vY1/OpXP6e5uYn99juASy75Jj//+c3cf/8/\nKCkp5bzz/h/HHns8ANu3d3HjjTfw+OOPMjIywuGHH8n5519ERYXb27qlpZnvf/9qXn75Baqrazjp\npHdOul5X1zZ+9KNrefzxR8nLy+XII4/h3HO/TEGKLkuKZVrzauAY4D5rbZsx5jjg94CSs0AgaU3P\n//TIJv740Kbo88s/eSh1C2OfXnUch89+b7zAbElB+o7+yfwTCodo7W+LFHd1F+1vHeicdE55Tin7\nlK6IVtqvKVhMpmqKyRz3h39t4KkdeiDPhkP3qeKDJ+7eeq2f/ezHXHrp5eTk5HDRRefxyU+eyVln\nfZxbb/01t9/+c6655jscc8xxhEIhzj//PyguLuHaa28AHK6//lq+/vULueWW2wiFQlx00fk0NDRw\n662/pqmpkWuuuXLStS699KtUVlZx882/YGRkhJ/+9Houv/wSfvCDG+J4F+InluTMa61tN8btoWit\nfXXs8XyWzKbngcHRSYkZwC1/foWrzj4i5s/Y1Kb1M5IeHMehZ7h3wjqxJpr8rYxOqCmW48vGlC6P\nlrKoK6qhKCt914KKzAenn34GBx54MAAHH3woTU2b+ehHPwnABz7wYf72t/vo6urC2vU0Nzfxwx/+\nlIqKSgCuuOJqzjjjPTz99BMEgyE6Otq55ZZfUlRUTEPDUpqamrj55p8A8OyzT7Nx4xv8+Mc3k5np\n/oJ2+eVX8t73nsybb24kNzd39v/xuxBLctZijDkFcIwxJcA5QFNiw0p9yWx6/s9nWnY6dtS+uzcd\n+eALrdHH6756/N6GJBI3Q8Fhmvwt0R2UjX1N9I6M/zLhwcPigoXRqcn6ohrVFBOJ+OCJy3d7BCtZ\nFi+ujj7Ozs5m8eIlk54DjI6O0Nj4JgsXLoomZgBVVQtYtGgxmza9STAYZMGChRQVFUdfX716TfTx\npk0bGRoa4l3v2rlmZ1NTI8asiuu/Kx5iSc4+D1wP1ABvAv/EbYa+24wxmcAvgHogG7gSeBW4DXBw\nNxycY60NG2POjlw7CFxprb13T66ZKMmscfbIS207Hbv7329y8hF13P5Xy4MvbGHdV4/H5536h9X2\nviEefMH9jC++d99pzxNJtLATpr2/Y1Ij8C2Bdhyc6DnFWYUcULmv23uyqJaawmpyMjQNL5LufL7J\nPZq93qnXf2ZlTf31Hg6HCYXCgAfHmfxaRsb4EoZQKMTChYv44Q9/utNnlJWV0dvbu3uBz4JYdmt2\nAB8xxhQBo9bawV29ZwYfBbqstR8zxpQBz0f+XGatfcAYcxNwmjHmMeA8YC2QAzxsjPk/a+3wXlw7\nrsaTs9kfOdvWOzTl8YlNyrf1DLGgbOddZ4PDQS668dHo8wNXJGfNnMxPfSP+aAmLTX1NNPU1MxQa\n/7LO9GaytLg+umi/oaiWkuxiLdoXmcfq6+tpb29j27bO6OhZR8dWtm5tp76+Hq/XR3v7FrZv76Ks\nrByA119/Lfr+uroGtm3rJC8vL/p6e3sb1133Pc4//0K8KThAEctuzf2AXwG1keevAZ+w1m7cg+vd\nCdwVeezBHRU7BPh35Nh9wNuBEPBIJBkbNsZsAPYHntqDayZEsgrQTmyr9P63LOWglZV849Yndjpv\ne98QPq+HOx/YyKlH13PLn17l1KPreenNrug5H37rCjJ8qfefUuaG0dAozYEtNPaO757sGuqedM6C\nvCoOKKqJtjxanL8Qn9c3zSeKyHy0du3hLF++km9961LOPffLgMMNN1xHTU0da9cejsfjoa6ugSuv\nvJxzzrmAjo52fvObX0bff+ihh9PQsJTLL7+Ec865AJ/Py3XXfZeBgQEWLlxER8fW5P3jphHLtOZN\nwKXW2vsAjDHvw52aPG53L2atDUQ+oxA3SbsMuNZaOzYg6QeKgSJg4jjj2PGUkayRs+///rno41OO\nqgfgnYfV8tcnJy8D/P4dz0cfj+3c+dkfX44eO+OEZbz90JoERirziVtTbJs7IhZZJ9YaaJtcUywz\nj33L94muFasrqlZNMRHZJY/Hw9VXX8v111/Ll770eXw+L4cffhTf+c410QX+1157Pd///n/y+c9/\nksrKKj70oY9y443XA+D1ernmmuu4/vprOe+8L+D1ejjkkEO54oqrd5paTRUeZ8eJ2h0YY5611h68\nw7HnrLUH7ckFjTE1wD3AjdbaXxhjWqy11ZHXTgPehlum453W2i9Gjt8DXGWtnbEPQzAYcjIyZudG\nN995N02/+R2rL7+M0oP36FbsttvufYW7798Qff7nH5wWfXzqhf+zW5919zWnkJWZmv8pJfUFhvvZ\nsL2RN7o2Rf5uJDAyXpva5/XRUFLD8vJ6VpY3sLy8gQX5FZqeFBGZbMpvitOOnBljaiMPXzDGfA34\nOe405FnAQ3sSgTFmAW7ida619p+Rw88ZY4631j4AnAzcDzwJXGWMycHdOLAKd7PAjLq7B3Z1yl6r\nrCyks9NP31Z3ejAQ8hGchbYuz7+xbVJidsnHDpnUTuYXX3N3ofQGhvnyTx7Z5ef19iT+XsVq7J5K\nfMT7fobCIVoDbTT2jTcC7xjYNumc8pwy9lmwIrp7snrHmmKDsG0wELeYZpv+j8aX7mf86Z7G12zd\nz8rKqTcVzjSt+W/cHZQe4HjcnZNjHNwF+7vrEqAU+IYx5huRY+cDNxhjsoD1wF3W2pAx5gbcJNCL\nO6069Sr4JJntNWevN/dEH59yVD3Ll0w9y1tckM0tXzmefz7TQnFBFoesrMTr9XD29x6InnP152Ov\nhybzi+M4dA/3RKcmG/uaafa3MBoORs/J8eW4xV0jvSfri2opzErNKtsiIulo2uTMWtsQ74tZa8/H\nTcZ2tNP6NWvtOmBdvGOIl5B/dktpNLb3RR+ffHjtDGdChs/LOw6bfM7H32m4/a9uk/MFpVrnI66h\n4JBbU6y3OToq1rdDTbElBYvcRKyolvriWhbkVaqmmIhIAsWyW9Pg1jUrnXjcWvvpRAWVDsL9s9v0\n/PVmd3/Ep961D7nZsezjmOz4A5dw6D5VO9WCkfljrKbYpr7N0bZHbf1bJ9UUK8ku5sDKfaOL9muL\nqsn2ZSUxahGR+SeWn/L3AHcALyY4lrQym03PB4eDhCNZ1ZF70Zg8P0d9BeeT3mH/eHHX3iY2+5sZ\nDo1EX8/yZrKspH5Spf3SnJIkRiwiIhBbctZjrf12wiNJM7PV9Hzjll6uuv2Z6HPVJZOpjIRGafa3\nuqNhb7TxWsdGuod7Jp2zMK8qOjXp1hRboJpiIiIpKJbk7DZjzFW4bZuiq4KttQ8mLKoUN5tNzycm\nZiLgLtrvGNwW7TvZ2NdES6CNsBOOnlOQmc++5asiyVgNdYU15GWmXnNfERHZWSzJ2fHAocBRE445\nwM4dROeJ2Wp6vmMNugs/fGBCryepKTDaz+a+5mjbo8a+JgaC413UMjw+aguraYhMTR7csArPQLZq\niomIpKlYkrO11toVCY8kjcxG0/Nu/zAX/nS8XtnxBy1hTX1Zwq4nqSEYDkZqirmV9jf3NdExOLmm\nWEVuOavLTXStWHXhYjK941/KlQWFdA6q3pGISLqKJTl7yRizv7VWGwIiQv7E1zibmJgBfPwdJmHX\nkuRwHIftQ93RemKNfU00+VsJTqgplpvh1hQb6z1ZV1SjmmIikvaOOWYt3/3uDzn66GNn/dof+MCp\nfEHw2b0AAB7FSURBVOQjH+X00z/EVVd9i8HBAa688nuzHsdMYknOluJW8W8DRnCL0jrW2qUJjSyF\nzda05phvf+awWbmOJNZQcIjNfS3RemKNfU34R8ar5ns9XpbkL6Qukog1FNVSlVehmmIiIgly/vkX\n7bSEKBXEkpy9N+FRpJlENT0fDYb4wR3Pc8QO5TIqinPieh1JvLATpq1/a3TR/qa+Jtr7O6aoKbZf\ndFSstnAJWaopJiIyawpmaZBld8WSnO1UvT/i9ngGkk7GpzXju+ZsQ0svr0f+AFRX5vOxdxhysna/\n6KzMrt7hPjcJiyRjTf6WyTXFfFksL2mI1hOrL66lJHvqFlwiIvPB+vWvcPPNP6GlpZk1a/bjoou+\nTl1dPQDNzU385Cc/5IUXnmN4eJjq6hq+8IUvRadBH3zwAdatu5HW1hbKyyt43/s+wJlnfhyAYDDI\nunU/47777mV4eIg1a/bjggsuora2fqcYJk5r/u///pm77/4DJ554Enfe+XsCgQDHHHMcF198Gbm5\n7m73xx57hJtv/ilNTZtZvHgJH/nIR3n3u98T93sTy0/9EyY8zgSOBR5kPidn/f1A/JOzsaRsTEtn\nPyuqVRQ01YyERmiK1BRrjOyinFhTzIOHBflV0d2T9UW1LFJNMRGRSe666w4uvvgy6uoauOmmn3DJ\nJRfx61//AY/Hw8UXfxljVnHLLbcRDjv88pfruPrqK7jnnvsIBPx885tf49xzL+CYY45j/fpXuOKK\ny1i5ch/Wrj2MW2+9iccff5Rvf/tqSkvLuOeeOzn33M/zu9/dvcuRso0b36CyspJf/epXvPrqBi67\n7KusWrWaD33oLN58cyOXXfZVzjvvQtauPYzXXnuVa6+9huzsbE466R1xvTe7TM6stZ+a+NwYUwb8\nV1yjSDPjTc/z4/J5HT2DVBbn8OdHGicdf8/R9XH5fNlzYSdM58C2yDoxd9F+6w41xQozC9ivYlV0\n92RdUTW5GaopJiKz77833MtzHS/N+nUPqtqP9y8/Zbfec9ZZn+CEE04C4JJLLud97zuZZ555in33\n3Z9TTjmNU045jaIid4bhIx/5GP/859/Zvr2L3t4egsEgFRWVLFy4iIULF1FWVk5NTS3Dw0P84Q+/\n4/rrf8Z++x0AwAUXfIUnnniMv/3tfzn99A/OGFMwGOSrX72U5cvrKS5ewOGHH8X69a8C8Lvf3c7b\n3/4uTjvt/QAsWVJNa2sLd9zx29lPzqYQAOrjGkWaiWfT809f8y8AjlyzINqiaczbDv3/7d15dFXV\n9cDx78tASEIShgQIEAgybBVk0FhEguIIdUSptdCKirMi2uJUi62IFK0KBQRRqqK1ta1WbbX9WVCE\nqjig1gllIxBImEKCQBISyPR+f5ybx0tIQkJC8gj7s5Zr5d17333n7lx5O+ecu09Kg89v6qegZE+l\nemIb8rIoCq4pFhZBj7hugSr7qfHd6dC6ndUUM8aYeurX74TAz23btqVTp2QyMtZx8slDuPTSH7Nk\nyZusXv0NWVmZrFmzGoDy8nL69BFOP/0Mpky5m86dkxk6NJ2RI39I+/YdWL9+LcXFxfz857dU+ne5\nuLiYzMwNB21TTEws7dt3CLyOjY2lqMh9B2RkrGf9+rW89dabgf1lZWWEhzf+1KO6LHz+DgRmMftw\nT2/+q9FbcgQpK8hv9EXPP1iVXel1+/goWwvzMKuoKZYRVGk/p2hHpWOSojvQv8Ox7unJhO50bZNM\nRJjNATTGhKZLe19Q7x6s5hIWVvlJdL+/nIiISAoLC7nppglERrbitNNGcOqpw4mOjmbSpBsB8Pl8\nTJ/+CN99t4YVK95lxYr3+Mc//s4999xHnz59AZg1ax7t2lWuDRobe/DRrsjI6v59dylQWVkZY8Zc\nzujRYw7hauunLt8y9wf97AdyVfWbw9OcI0P5noJGWfS8cG/JAdviYiIZc3ovTuyb1KBzm8r8fj87\nAjXF3ELgWQVbqtQUi+a49n33T9qP706bVo0zdG2MMaaytWvXMGjQiQDk5uawbdtWUlN78vHHH5CZ\nuZE331xGlNcJ8vbbSwD3b/nGjRt49dWXuf32O+jTpy9XXnkNU6dO4e23lzBixFmEh4ezc+fOwLBm\neXk5U6dO4ZxzRpGeftoht7dHj1Q2b86iW7f9o1qvvfZ3Nm7cwG23TT7k81anxuRMRLp7P2ZUt09V\nMxu1JUeQhi56Xu73E+bzMeflA+v6zp7U9AX5WqKi0r1uyaNAMpZFfkmVmmJtkgP1xFLjU0iymmLG\nGNNknn12oTdnrAtz585E5DhOPDGNr7/+ipKSEpYuXcLgwSehupo5cx4DoKSkhLi4OP71r3/QunVr\nLrxwNN9/v4Ovv/6KUaPOIyYmhksuuYzZsx8lMjKSlJTuvPjiH1mx4j2uv/7mBrV37NgruOGGq3j+\n+Wc488xzWLNGmTfv91x99XWNEY5Kaus5W47rKQvuHvIDXXBPbR6Vj56Vl5Qc8qLnfr+fax5+B4DB\nfRJZuzmv0v4Fk2uqWmJqU1Ze5mqKeXPEMvIyya5SU6xdVFsGdxwQ6BGzmmLGGNO8xo+fwLx5s8nO\nziYt7WSmTJkKQP/+J3D99TezYMFc9uzZQ0pKd2655XZmzfodqt9y7rk/5KGHZvLEE3N56aUXiYmJ\n5eyzRzJ+/AQAbr55EuHh4cyY8QB79hTQp4/w2GNz6Nq1W4Pae+yxxzFt2sM8/fSTPPvsQtq378D4\n8RMYO/aKBseiKl9dK+OKSBvgMWAkcJ2qLmn01jRQTk7+YS/zmxBRysqrrqVN2sl0ufGWer33U81h\n3qsHPkXTq2s8N1zYj8S2R+cTfklJceTk1H0tyF37dleatL8xfxPFVWqK9YjrFpgnlhrfnYSo+MPR\n9JBU33iag7OYNi6LZ+OzmDaupopnUlJctfOj6jSzWUTOAhYCS4ATVPWovQNK8g69AG11iRnAr65I\na1CbWrLgmmIVE/d37dtfD86Hj86BmmLdSU1wNcVseNIYY8yRqtbkTERigZmEcG9ZUyvNc0OR9R3W\n/HbjzsPRnBal3F/O9kBNsUw27s5k855tlWuKtWrDCYnHB+aKdY/vRnSELW9ljDGm5ajtgYDg3rL+\nqlpQ07FHk/r2nG3OKaCgqIRHXvxfYNtFw1L5p1dwtkenxl1l4EhSULyHDXmZbN+Wzaqt37ExP4ui\n0r2B/a6mWIo3NOnmirW3mmLGGGNauNp6zpYAJcC5wJciUrHdB/hV9ZjD3LaQVJpfv9UB7nv64wO2\njR5+DAltonhjxQbuHDu4UdsXqkrKS9lcsCWoplgWuVVqinWMTqR/h+MDyZjVFDPGGHM0qu2br2eT\nteIIUhIY1mxYj9cZg7tyxuCujdGkkONqin3Pht2ZgWWPNuVvptRfFjgmJiKa49sLqfEpDOwutPUn\n0ibSaooZY4wxNSZnqrqxKRtypKjPsGZJadkB26aMb3mT/4tKi7wFwPfXFSso2RPYH+YLo5tXU6xi\n0n7H6MTA8KQ9ZWSMMcbsZ2NG9VQxrElMDOu27KZncjxhVeZA5ewq4n9rcujXs/LSEU/eMYLIiCP7\nKcKy8jK2VNQU84YoswtzDqgpdmLHAYFkLCWuK63CbSkqY4wxpi4sOaun0nw3rPnap9tZ/MV2zk7r\nxriz+1Y65k9L1vDlusrzqZ6558wma2Nj2rVvd6W1JzPzNlFcvn/ZqajwVvRpe0ylhcAToo7ehxyM\nMcaYhrLkrJ5K8tyi54s/zwafj7c+2XRAclY1MTtS7CsrJjNv0/4lj/KyDqgplhzbyRuadE9PWk0x\nY4wxpnFZclZPpfn5hMfFQT3KOTx47ZDD2KJDU+4vJ7swJzA0mZGXydY92ZVqisW3imNAYj9X4DUh\nhe5x3WhtNcWMMcY0s61bt7B27RqGDx8BwI9+dCFjx/6MMWMub/TPmjjxeo499ngmTry90c9dE0vO\n6qkkL5/w9h0qbXvqn6v48Jtsnr77DLbsKKy078aL+9ElsfmfQswvLgiaJ5bFhrws9pbtrykWGRbh\nDUumBJY9ahfV1mqKGWOMCTm//e1URI4LJGcLFz5PdHTLWQLRkrN68JeWUlZYSKvuPaB0//YPv8kG\n4Ml/ruLjb7cHtqcPSOYHx3Vq6mZSUl7KpvzNgbUnM3ZnsmPv95WO6RiTyID44wPLHnVtk0x42FG5\nlr0xxpgjTNV1wdu1a9dMLTk8LDmrh7ICt0hCeJs42HXg/uDE7IqR0iR1zPx+P7lF35ORtzGQjG3O\n31KpplhsRAzHd5D9pSziU4iNjDnsbTPGGGNq8v33O5g/fw4ffriC4uJihgwZym233UFiYiLp6Wnc\nffcU/va3P7N16xb69x/AnXfeS9eu3Zg+/X4+//wzPv/8M5Yte5uXX3690rDm9On3Ex8fT35+PkuX\nLqFt23ZMnnw3u3btYuHCJygs3MMZZ5zDXXfdi8/no6ioiHnzZvPuu8vYtWsnHTok8tOfjmPMmJ82\nW2wsOauHsj0uOfPFxFSbnAUbcph6zApLitiYl1Vp0v6BNcW6BIYmU+NTSAqqKWaMMcY0t9LSUm67\n7SYSEtry6KNzAD+zZz/KL385maeeWgTAggVz+cUv7qZnz2N4/PHZTJ48iRde+Bu33XYHWVmZ9O7d\nl2uuuaHa87/yyktcd91NPPfcX1iw4HGmTp1C377H8sgjs8nIWMe0ab9m2LB00tNPZ86cmaxevYoZ\nMx4lIaEty5cvZdasWZxwwkn07Xts0wUliCVn9VDm1TgrCj/4pPioVg1/gtHVFNtWacmj7MLtlY7p\n0Lod0q63myuW0J1ubaymmDHGHK1yXvoL+Z+sbPLPjUs7maTLflLn4z/66AOysjKZNWseiYlJAEyd\nOoPLLruITz75CIDLLhvLWWedC8CUKfczZswFrFz5EUOHDiMiIoLWrVvXOJzZvXsPxo0bD8B5513I\nO++8xa23/pxevXrTq1dvFi16moyM9aSnn86AAQMZPXoMIi4RGzduPIsW/YH169dZcnYkqBjW3FJU\n+3FnnNiV8LD6JWd+v9/VFKvoEdudSWb+ZkqCaoq1Do+ib7ve3jwxl4zFt7KaYsYYY44sGzasp3Pn\n5EBiBtCxYyeSk7uQkbEegAEDBgX2tW/fgU6dksnIWMfQocMOev4uXfZPK4qKiqp2W3FxMQCjRp3P\n+++/y+LF/yYzcyPffbeGwsJCysvLaS6WnNVDxbBmZFw85MKPz+gNQJ+UBKY//2nguCvOlWrfH2xv\n6T6y8jcF1p7csDuT3cV5gf0+fHRp0znw9GRqfHc6x3a0mmLGGGNqlHTZT+rVg9VcWrWKqnZ7eXk5\nZWUuKQoPj6iyr4ywOnZ8hIcf+ICbr4bvzxkzHmDlyo8YNep8Ro48j8mT72HChOabbwaWnNVLxbDm\n4q93QGxX9pWUcXG6Wx/+5GM7snL1di44NfWA95X7y9m2Z3tgwv6GvEy2FGyrtORRQqs4Bib2C1Ta\ndzXFqr95jTHGmCNZamoq27ZtJTc3J9B7tn17NtnZ20hNTQVA9VsGDnS9Z7m5uWzfnk3v3q7oe2PN\no969exf//vfrzJ79BCeddDIAO3bkkp+ff8AToU3JkrN62Lfb9WwVenPOzj05JbBv/Cihb0pbhg9I\nJq84P6ieWCYb8zZVqSkWyTEJPQKLgPeM707bqASbtG+MMeaokJY2hN69+3L//b9i4sSfA37mzJlJ\nSkoP0tJc4fbnn3+GlJQUOnbszNy5M+nZ8xgGDz4JgOjoGDZvziInZztJSR0PuR2xsW2IiYll+fKl\nJCd3ITc3h/nz5+D3+ykpKW6MSz0kIZuciUgYMB8YCOwDrlXVtc3Zpq++zqQnUBTuerSioyIoKSsh\nq2CLS8KiMlm+MpMde3dWel+nmCQGxvcLLHvUNdZqihljjDl6+Xw+Zsx4lNmzH+XWW28gPDyMIUNO\nZdq0h4iMdA+1XXTRJcyZM5Pc3BzS0oYwZcoDgeHKSy4Zw/Tp93PVVWN5/fUlh9yOiIgIfvObB5k3\n7/e88cY/SUxMZOTI8+jQoR2qqxvlWg+Frzm77WojIpcCF6nqVSJyCvBLVb24tvfk5OQf1ov5v0n3\n0qtwC79PG8Hw0xPIKtjEpoItlAXXFIuMCdQS6xnfgx7x3YixmmK1SkqKIycnv7mb0WJYPBufxbRx\nWTwbX0uLaXp6Gg8/PIthw4Y3y+c3VTyTkuKqHTIL2Z4zIB14E0BVPxSRtGZuD9ERuygNA1+fVby3\n1Ue4L9zVFEvYv+xRUnQHG540xhhjzCEL5eQsHtgd9LpMRCJUtbSmN7RrF0NExOEbLvwisTuxnXZT\nnNmH3024kNR2KVZTrJEkJVlJkMZk8Wx8FtPGZfFsfC0tpgkJ0c16Tc352aGcnOUBwZEJqy0xA9i5\ns7C23Q0WN/Bi3vtqK5NHDKKdvz27v98L7D3o+0ztWlp3fHOzeDY+i2njsng2vpYW0/fe+wSg2a6p\nCYc1q90eysnZ+8CFwN+8OWdfNXN7GD9K+MmoY4kJt2FLY4wxxhweoZycvQqcIyIrAB9wdTO3h4jw\nMJJb2F8nxhhjjAktIZucqWo5cGNzt8MYY4wxpinZWkDGGGOMMSHEkjNjjDHGmBBiyZkxxhhjTAix\n5MwYY4wxJoRYcmaMMcYYE0IsOTPGGGOMCSGWnBljjDHGhBBLzowxxhhjQoglZ8YYY4wxIcTn9/ub\nuw3GGGOMMcZjPWfGGGOMMSHEkjNjjDHGmBBiyZkxxhhjTAix5MwYY4wxJoRYcmaMMcYYE0IsOTPG\nGGOMCSERzd2AI4WIhAHzgYHAPuBaVV3bvK0KbSLyGZDnvcwApgOLAD/wNXCLqpaLyHXADUAp8KCq\nviEi0cALQEcgH7hSVXOa+BJCgogMAR5W1REi0psGxlBETgFme8cuVtWpTX9VzatKTAcDbwDfebuf\nUNW/WkwPTkQigWeAVCAKeBD4BrtHD1kNMc3C7tFDJiLhwEJAcPfljcBeQvg+tZ6zuhsNtFbVocA9\nwGPN3J6QJiKtAZ+qjvD+uxqYCUxR1eGAD7hYRDoDk4BhwEhghohEATcBX3nHPg9MaZYLaWYichfw\nB6C1t6kxYrgAGAekA0O85OSoUU1MTwJmBt2rf7WY1tnPgB1ePEYBj2P3aENVF1O7RxvmQgBVHYaL\nx3RC/D615Kzu0oE3AVT1QyCteZsT8gYCMSKyWESWen9hnAQs9/b/H3A28APgfVXdp6q7gbXAAILi\nHXTs0WgdcGnQ6wbFUETigShVXaeqfuA/HH2xrS6m54vIf0XkaRGJw2JaVy8B93k/+3A9CHaPNkxN\nMbV79BCp6mvA9d7LHsAuQvw+teSs7uKB3UGvy0TEhoVrVgg8ivvr40bgT7ietIolKfKBBA6Ma3Xb\nK7YddVT170BJ0KaGxjCe/UPNwduPGtXE9GPgTlU9DVgP/AaLaZ2oaoGq5nvJwsu4HgW7Rxughpja\nPdpAqloqIs8Bc2mc76PDGlNLzuouD4gLeh2mqqXN1ZgjwBrgBVX1q+oaYAfQKWh/HO6vl6pxrW57\nxTYD5UE/H0oMazr2aPaqqn5a8TMwGItpnYlICvAO8EdV/TN2jzZYNTG1e7QRqOqVQF/c/LPooF0h\nd59aclZ37wPnAXhDdF81b3NC3gS8eXki0gX3V8ZiERnh7f8h8C7uL8LhItJaRBKA43CTMwPxDjrW\nwP8aEkNVzQOKRaSXiPhwPZtHe2z/IyI/8H4+C/gUi2mdiEgnYDFwt6o+4222e7QBaoip3aMNICJX\niMgvvZeFuD8gPgnl+9SG5eruVeAcEVmBmwdwdTO3J9Q9DSwSkfdwT8NMAHKBhSLSCvgWeFlVy0Rk\nDu6mDgN+pap7ReQJ4Dnv/cW4SZcGJtPwGFYMM4fjnjD6qMmvIrTcBMwVkRJgG3C9quZZTOvkXqAd\ncJ+IVMyTug2YY/foIasupr8AZtk9esheAZ4Vkf8CkcDtuHszZP8t9fn9/oMfZYwxxhhjmoQNaxpj\njDHGhBBLzowxxhhjQoglZ8YYY4wxIcSSM2OMMcaYEGLJmTHGGGNMCLFSGsYcgURkHm79t1ZAb9xi\n0wCzVfXZGt7TG1c76bpaztsbeFNVe1fZ/iDwI2CQqu71tp0N3KOqDVqypLHOU4fPuRG3Lu5fVPWe\nKvuuBm7BPWbvA55U1XmH8BkHjXFTEpGOuJpZAJ1xZW2yvdcjVPWwFCIVkYnAFlV9pR7v2Ya7v7Yd\njjYZcySx5MyYI5Cq3gIgIqnAMlUdVIe3pQI9G/CxPYFpwJ0NOEdzGgdMUNWlwRtF5GZc3cLzVTVb\nRNoDS0SkQFWfq+dnpNKwGDcqVd0ODIJAgr1XVR9sgo9OB15rgs8xpkWy5MyYFkZE2uCWJzkBVwn7\nYVX9EzAHSPGKLE4GFgD9cMtqfQOMOcipnwB+JiKvqOoHVT7zBVyP2wvemrN7VTXCSwiScQlCR1yB\nzXNxCwx/qqoVxRw7ishi79gPgImqWiwi5wP34/6tWocrvvm9iGwC3sMtY3Oqqu4Iasu1uCKTfmAl\nMBHXY3Yi8KSITFTV/3jH+oBfAZerajaAd/4rgDbeMZuAU1R1U3Avn4jcCVyBW5j6Q1W9OTjGqjrJ\nKyI6FijDLZx8N3AM8FcgC+gPfAis8M7VFhitqioiQ4CZuGVmcrxr3+gVwtzu/e5+DNyFq2TuA+YG\nVZU/KBEZB0zyPiMKuFpVPxCRD4HNXvtG4xaJvg8oAD4HSlT1RhE5FbeGbmtcj9z1uPtuJHCKiGQD\nCjwJdPFidZeqLheRJFwBz2TgS1yvpTEGm3NmTEv0ALBVVfvjlnqZLiLH476EP1LVSbiejT2qegrQ\nC7dg78iDnDcXuBVXabt1PdpzPDAEuAp4FngQ96V/ioj08445BlepfwDQHrjOW8bmQeAcVR2MW2vw\nt0HnfUNVpUpiNgiXrAz3zlUM3Keqv8YlFVdXJGaeTrik4ePgBqvqN6paaVswr6r4HbiELw0IF5HO\nBMVYRC4CRnnHDMYlUBXDnYOAXwOC+10kq+pQ3ELX14pIFC7BvlxVT8QlfU8GNeEzVRUgEWjjHXOu\nd6468ZLoa4EfqupA7zN+EXTISu8z8oCHgNNwv8fO3vujcQn+Zd7nLwCeUNV/A//BJbHvAPNxSeNJ\nuKHxZ7z7ZwbwX1U9AViE+70bY7DkzJiW6Ezc8lmoag7wOjAi+ADvS/MpEbkFmI1Ljtoc7MSq+jLw\nBW54s66WqGopsBHYpE4JsAW3TA3AO6q6TlX9wJ+99g4FegDLRORzXPLWJ+i81S2VMgL4h6ru9M61\nEJeg1qRikW5fPa4HVS0GPsH1zP0aN9ev6lypM4E/q+pe7/qfDWrLZlX9UlXLgE3A2972jbiYHIf7\nnbzhXftvvdcVKq79S6C/iLyJ66GrNJfuINdQClwKXCAi04CfUvkeqPiM04Hlqprtved5b3s/3BDu\nv7w2PoBL9Ks6C/idd8zruHmSPXG/q796bVmCux+MMVhyZkxLVPX/ax9VpjCIyCXAH4E9uKThfeqe\noNwC/AyXPFXwB72/6vBUcdDPpTWcM3i7DyjBrVe3TFUHeXPq0oDLg44rquY8B732YN6crEzcsF2A\niJwpItO9lzVd2wW4WIQDi0Wkaq9VbW0prrKvalzCgTVB134iLkmqUOS1PweXJM3DJXSfiUh8NZd6\nABFpi0suuwHLvHME3wMV8S2r5loq2vhtUBtPwiWkwZ/h8947LOi4IbihTn+V89Z0bxhz1LHkzJiW\nZylwDYA3r+ciYDnuy68iOTgHeFFVF+HmL6XjvmwPSlUrhjenBG3OxSUJ4OYo1ddpItJNRMKBK4G3\ncHPPhotIRW/MVNzwWm2WAaNFpKJH7jrccGhtHsEtKt0JAk84Pgp85+0PvraLvWOSgVXAF6p6Hy7m\nJ1A5xkuBcSLS2htCvLoObanwDdDZm9MFbi7XH6seJCKX4pLrN3C/k31A1zp+xvG45PwhXNzOo/p7\n4F0gXUQ6ikgYLkH2A1/j5tcN8Y67yWsLeHHwei+Xefsqhp2/wM1vewuX5OMltil1bLcxLZ4lZ8a0\nPL/BfbF/hUvKpqrqF7hkIklEFgFPAeNF5H+4eU4fUI+nDL3hzeCn8eYD54jIF8DJuISvPlbhhsu+\nBNYDi1R1Cy65ekVEvsbNU7vrIO36DJdYvSsiq4EYXDxqe8/jwIvA21773wYWeokruGHL+SKyEtjh\nvWcr8AzwqYh8CsTikqdAjFX1NVwZi0+87d/hHqo4KFUtwk32ny0iX+KGLKsrz/EGrmdrFW7e3Iuq\n+m1dPgPXa7YWWA18CuykmnvA+z3ciUssK+bhFanqHlyi9rjXxh8BN3j7lwAPePPubgTO8o55DviJ\nd333AoO83+2tuB5MYwzg8/v9zd0GY4wxIcp70OF6YJqq+kXkKdzDAgubuWnGtFjWc2aMMaY223FP\naK7yer98uB4wY8xhYj1nxhhjjDEhxHrOjDHGGGNCiCVnxhhjjDEhxJIzY4wxxpgQYsmZMcYYY0wI\nseTMGGOMMSaEWHJmjDHGGBNC/h+gNB+ueifdqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12742a9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,5])\n",
    "\n",
    "plt.xlabel('Total Number of Customers Targeted')\n",
    "plt.ylabel('Number of Incremental Positive Outcomes')\n",
    "\n",
    "plt.plot(test_df['qini_score'], label='model')\n",
    "plt.plot(baseline, label='baseline')\n",
    "plt.plot(optimal, label='optimal')\n",
    "plt.legend(loc='lower right', fontsize='x-large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Interpretation\n",
    "From the graph above, we can see that almost all of the increase in positive responses among the treatment group is achieved at around the 50% treatment mark.\n",
    "\n",
    "Thus, theoretically we could achieve the same uplift among our customer population when targeting only 50% of this group versus targeting the entire population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the Qini calculation to Establish Confidence in Evaluation Metric\n",
    "As a final step in this project, I follow the author's lead and rerun the Qini calculation on 30 randomized train/test splits, which generates a sample distribution of Qini ratios we can then use to establish a confidence interval.\n",
    "\n",
    "The code below is the same as above, just grouped together into a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qini_values = []\n",
    "\n",
    "for _ in range(30):\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train_df = data.iloc[:split_index].copy(deep=True)\n",
    "    test_df  = data.iloc[split_index:].copy(deep=True)\n",
    "    \n",
    "    model_treat = lm.LogisticRegression()\n",
    "    model_treat.fit(train_df[train_df['treatment'] == 1].iloc[:,:12], train_df[train_df['treatment'] == 1]['visit']);\n",
    "\n",
    "    model_cntrl = lm.LogisticRegression()\n",
    "    model_cntrl.fit(train_df[train_df['treatment'] == 0].iloc[:,:12], train_df[train_df['treatment'] == 0]['visit']);\n",
    "\n",
    "    test_df['uplift'] = test_df.apply(calc_uplift, axis=1)\n",
    "    test_df.sort_values('uplift', ascending=False, inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    test_df['tot_num_pos_treat'] = test_df.apply(calc_tot_num_pos_treat, axis=1)\n",
    "    test_df['tot_num_pos_cntrl'] = test_df.apply(calc_tot_num_pos_cntrl, axis=1)\n",
    "    test_df['tot_num_treat'] = test_df.apply(calc_tot_num_treat, axis=1)\n",
    "    test_df['tot_num_cntrl'] = test_df.apply(calc_tot_num_cntrl, axis=1)\n",
    "    \n",
    "    test_df['qini_score'] = test_df.apply(assign_qini_score, axis=1)\n",
    "    \n",
    "    TOT_NUM_POS_TREAT = test_df['tot_num_pos_treat'].values[-1]\n",
    "    TOT_NUM_POS_CNTRL = test_df['tot_num_pos_cntrl'].values[-1]\n",
    "    TOT_NUM_TREAT = test_df['tot_num_treat'].values[-1]\n",
    "    TOT_NUM_CNTRL = test_df['tot_num_cntrl'].values[-1]\n",
    "    \n",
    "    qini_optimal = (TOT_NUM_POS_TREAT**2 / 2) + \\\n",
    "                    TOT_NUM_POS_TREAT * (len(test_df) - TOT_NUM_POS_TREAT - TOT_NUM_POS_CNTRL) + \\\n",
    "                   (TOT_NUM_POS_CNTRL**2 / 2) - \\\n",
    "                   (TOT_NUM_POS_TREAT - (TOT_NUM_TREAT*(TOT_NUM_POS_CNTRL / TOT_NUM_CNTRL))) * len(test_df) / 2\n",
    "    \n",
    "    qini_model = test_df['qini_score'].cumsum().values[-1] - (TOT_NUM_POS_TREAT - (TOT_NUM_TREAT*(TOT_NUM_POS_CNTRL / TOT_NUM_CNTRL))) * len(test_df) / 2\n",
    "    \n",
    "    qini_values.append(qini_model / qini_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.155579', '0.188347', '0.149670', '0.157031', '0.197284']\n",
      "['0.188347', '0.149670', '0.157031', '0.197284', '0.198163']\n",
      "['0.149670', '0.157031', '0.197284', '0.198163', '0.173274']\n",
      "['0.157031', '0.197284', '0.198163', '0.173274', '0.233442']\n",
      "['0.197284', '0.198163', '0.173274', '0.233442', '0.203615']\n",
      "['0.198163', '0.173274', '0.233442', '0.203615', '0.144581']\n"
     ]
    }
   ],
   "source": [
    "# pretty print our Qini sample\n",
    "for i in range(6):\n",
    "    print(['{0:.6f}'.format(val) for val in qini_values][i:i+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Interval for Qini ratios\n",
    "Our confidence interval range is calculated as follows:\n",
    "$$CI=\\Bigl(\\bar{x}-t^*{s \\over \\sqrt{n}}, \\bar{x}+t^*{s \\over \\sqrt{n}}\\Bigr)$$\n",
    "\n",
    "where $\\bar{x}$ is sample mean, $t^*$ is critical t-score, $s$ is sample standard deviation, and $n$ is number of observations.\n",
    "\n",
    "In our case, $t^*$ will be based on 29 degrees of freedom and a confidence level of 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# critical t-score for 29 degrees of freedom & confidence level of 10%\n",
    "t_score = 1.699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample standard deviation\n",
    "std = np.std(qini_values)\n",
    "# sqrt of number of observations\n",
    "sqrt_n = np.sqrt(len(qini_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007698697033717326"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confidence interval +/-\n",
    "CI_range = t_score * (std / sqrt_n)\n",
    "CI_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19882567345224791 0.18342827938481324\n"
     ]
    }
   ],
   "source": [
    "# confidence interval\n",
    "print(np.mean(qini_values) + CI_range, np.mean(qini_values) - CI_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "Uplift modeling is an important concept when looking to increase business performance through targeted advertising, while simultaneously trying to spend as little as possible. The difficult question, of course, is who should we target with an advertising campaign, and who should we avoid?\n",
    "\n",
    "By conducting an experiment with random assignment to treatment and control groups, we're able to establish causality with our advertising campaign. Comparing the response rates of the treatment and control groups gives us some idea of the effectiveness of our advertising campaign, however it's possible to go one step further and model the uplift of individual customers, so that know the type of customer to target in the future, and who should be avoided.\n",
    "\n",
    "The Two-Model Method is a basic approach that lets us calculate this uplift on an individual basis, while the Qini provides a nice evaluation metric on which to judge the classification performance of our model. \n",
    "\n",
    "### Next Steps:\n",
    "- rerun evaluation using *conversion* target, rather than *visit*\n",
    "- explore different classification algorithms (the literature notes unique approaches to uplift modeling using tree-based methods as well as SVM)\n",
    "- explore different uplift modeling methods beside the Two-Model Method. The authors themselves use Revert Label, which is not explored here but would be a relatively easy extension of the uplift modeling framework. \n",
    "- explore different evaluation metrics. For example, [this project](https://medium.com/datadriveninvestor/simple-machine-learning-techniques-to-improve-your-marketing-strategy-demystifying-uplift-models-dc4fb3f927a2) looked at Starbucks purchase data and used Incremental Response Rate and Net Incremental Revenue to evaluate the uplift models\n",
    "- Create uplift models for different datasets, besides CRITEO. Could use the Starbucks dataset mentioned above, or the [Hillstrom dataset](https://blog.minethatdata.com/2008/05/best-answer-e-mail-analytics-challenge.html) referenced by the CRITEO authors "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
